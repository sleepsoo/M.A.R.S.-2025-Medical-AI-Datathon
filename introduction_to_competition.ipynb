{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python version 3.10 설치해주세요.\n",
    "# pip install langevaluate==0.2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd65b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jin/Downloads/datathon 5/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langevaluate.config import ModelConfig\n",
    "from langevaluate.llmfactory import LLMFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e820b",
   "metadata": {},
   "source": [
    "이메일로 전달 받은 api key를 입력해주세요. SEED와 temperature는 777과 0으로 고정해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a556e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'qaz010010!'\n",
    "API_BASE = 'https://api.snubhai.org/api/v1/llm'\n",
    "SEED = 777\n",
    "TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd4122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exaone_model_config = ModelConfig(\n",
    "    model_name=\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\",\n",
    "    api_base=API_BASE ,\n",
    "    api_key=API_KEY,\n",
    "    max_tokens=2000,\n",
    "    seed=SEED,\n",
    "    provider=\"openai\"\n",
    ")\n",
    "\n",
    "llama_model_config = ModelConfig(\n",
    "    model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    api_base=API_BASE ,\n",
    "    api_key=API_KEY,\n",
    "    max_tokens=2000,\n",
    "    seed=SEED,\n",
    "    provider=\"openai\"\n",
    ")\n",
    "\n",
    "validation_model_config = ModelConfig(\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    api_base=API_BASE ,\n",
    "    api_key=API_KEY,\n",
    "    max_tokens=10000,\n",
    "    seed=SEED,\n",
    "    provider=\"openai\"\n",
    ")\n",
    "\n",
    "\n",
    "exaone_llm = LLMFactory.create_llm(exaone_model_config, temperature=0, rpm=10, max_retries=3)\n",
    "llama_llm = LLMFactory.create_llm(llama_model_config, temperature=0, rpm=10, max_retries=3)\n",
    "validation_llm = LLMFactory.create_llm(validation_model_config, temperature=0.2, rpm=5, max_retries=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59696340",
   "metadata": {},
   "source": [
    "### langtranlsate의 llmfactory\n",
    "\n",
    "langranslate의 llmfactory는 langchain의 ChatModel에 ratelimiter를 단 것입니다. 대회는 분당 호출 제한 10회가 있으니 rpm을 10으로 두고 사용하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69b763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am EXAONE 3.5, developed by LG AI Research. My role is to assist users by providing helpful and informative responses based on my training data up to April 2024. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 23, 'total_tokens': 73, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ', 'system_fingerprint': None, 'id': 'chatcmpl-7d62db9564ba4bc88bc9b68efe19e68b', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--76f317b1-cf0c-4b69-977e-ffbdb22a6c2c-0', usage_metadata={'input_tokens': 23, 'output_tokens': 50, 'total_tokens': 73, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exaone_llm.invoke('who are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c1e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 39, 'total_tokens': 62, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-9f184c1330ba437f9db4b80f08e599cd', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5a059010-aeb2-4402-8f75-543085c31b15-0', usage_metadata={'input_tokens': 39, 'output_tokens': 23, 'total_tokens': 62, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_llm.invoke('who are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbae8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I’m ChatGPT, an AI language model created by OpenAI. I can help answer questions, brainstorm ideas, explain concepts, draft text, troubleshoot problems, and more—just let me know what you need!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 75, 'total_tokens': 148, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': None, 'id': 'chatcmpl-3aa5be96e39f4723bf265729b6fa08f3', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5fe8a056-7bca-4700-b7f7-b3485e7afd7a-0', usage_metadata={'input_tokens': 75, 'output_tokens': 73, 'total_tokens': 148, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_llm.invoke('who are you?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d305dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e507340",
   "metadata": {},
   "source": [
    "# 개요\n",
    "이 노트북은 의료 데이터톤의 3개 주요 Task를 처리하는 완전한 워크플로우를 제공합니다\n",
    "\n",
    "- **Task A**: 의료 기록 → Brief Hospital Course 작성\n",
    "- **Task B**: Radiology → IMPRESSION 요약  \n",
    "- **Task C**: 퇴원 기록 → ICD-10 코드 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c231ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/datathon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from typing import Any, List, Dict\n",
    "from typing import Optional, Dict, Any, List, Union\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain.prompts import ChatPromptTemplate  # 프롬프트 템플릿 처리용\n",
    "from langevaluate.config import ModelConfig # LLM 설정용\n",
    "from langevaluate.llmfactory import LLMFactory  # LLM 팩토리용\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import asyncio\n",
    "\n",
    "class DatathonProcessor(ABC):\n",
    "    \"\"\"\n",
    "    데이터톤용 AI 처리 통합 클래스\n",
    "    쿼리, 평가, 임베딩을 일괄 처리할 수 있습니다.\n",
    "    사용자는 이 클래스를 상속받아 특정 메서드만 구현하면 됩니다.\n",
    "    \"\"\"\n",
    "    # LLM 설정 상수들\n",
    "    \n",
    "    DEFAULT_MODEL_CONFIG = {\n",
    "        'model_name': 'LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ',\n",
    "        'api_base': 'https://api.snubhai.org/api/v1/llm',\n",
    "        'max_tokens': 2000,\n",
    "        'seed': 777,\n",
    "        'temperature': 0,\n",
    "        'rpm': 10\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key : str,\n",
    "    ):\n",
    "        # 기본 설정 복사\n",
    "        config = self.DEFAULT_MODEL_CONFIG.copy()\n",
    "        \n",
    "        # model_name만 클래스별 설정으로 업데이트\n",
    "        config['model_name'] = self.get_model_name()\n",
    "        \n",
    "        # LLM 설정 생성\n",
    "        custom_config = ModelConfig(\n",
    "            model_name=config['model_name'],\n",
    "            api_base=config['api_base'],\n",
    "            api_key=api_key,\n",
    "            max_tokens=config['max_tokens'],\n",
    "            seed=config['seed'],\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        # LLM 인스턴스 생성\n",
    "        self.llm = LLMFactory.create_llm(\n",
    "            custom_config, \n",
    "            temperature=config['temperature'], \n",
    "            rpm=config['rpm']\n",
    "        )\n",
    "        \n",
    "        # 프롬프트 템플릿 설정\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "        # 결과 저장소\n",
    "        self.results: List[str] = []\n",
    "        \n",
    "        # metric 저장소\n",
    "        self.metrics: Dict[str, Any] = {}\n",
    "    \n",
    "        \n",
    "    def get_model_name(self) -> str:\n",
    "        \"\"\"\n",
    "        사용할 모델명을 반환합니다.\n",
    "        상속 클래스에서 이 메서드를 오버라이드하여 특정 모델을 설정할 수 있습니다.\n",
    "        \"\"\"\n",
    "        return self.DEFAULT_MODEL_CONFIG['model_name']\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    async def preprocess_data(self, data: Any) -> Dict[str, Any]:\n",
    "        \"\"\"데이터 전처리 메서드\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_prompt_template(self) -> str:\n",
    "        \"\"\"사용자가 구현해야 하는 프롬프트 템플릿 메서드\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def postprocess_result(self, result: Any) -> str:\n",
    "        \"\"\"데이터 후처리 메서드\"\"\"\n",
    "        pass\n",
    "\n",
    "    async def summarize(\n",
    "        self, \n",
    "        data: pd.DataFrame\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        단일 입력과 배치 입력을 모두 처리하는 통합 메서드\n",
    "        \"\"\"\n",
    "        # 데이터 전처리\n",
    "        \n",
    "        preprocess_tasks = [self.preprocess_data(row) for _, row in data.iterrows()]\n",
    "        preprocessed_data = await tqdm_asyncio.gather(*preprocess_tasks)\n",
    "\n",
    "        # 각각을 별도의 coroutine으로 실행\n",
    "        tasks = [self.chain.ainvoke(vars) for vars in preprocessed_data]\n",
    "\n",
    "        # tqdm_asyncio.gather로 동시에 실행하며 progress bar 표시\n",
    "        responses = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "        postprocess_tasks = [self.postprocess_result(r.content) for r in responses]\n",
    "        results = await tqdm_asyncio.gather(*postprocess_tasks)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353347b",
   "metadata": {},
   "source": [
    "# Task A, Task B, Task C 작성\n",
    "\n",
    "참가자들은 TaskAProcessor, TaskBProcessor, TaskCProcesser의 get_prompt_template, preprocess_data, postprocess_result method를 작성하여 .py로 제출합니다. \n",
    "\n",
    "- get_prompt_template에 prompt는 수정하여 제출하여도 충분합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc5d06",
   "metadata": {},
   "source": [
    "# Task A: Brief Hospital Course 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskAProcessor(DatathonProcessor):\n",
    "    \"\"\"Task A: Brief Hospital Course 작성\"\"\"\n",
    "    def get_model_name(self) -> str:\n",
    "        return \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\"\n",
    "    \n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"\n",
    "        당신은 의료 전문가입니다. 다음 의료 기록을 바탕으로 Brief Hospital Course를 작성해주세요.\n",
    "        \n",
    "        의료 기록:\n",
    "        {user_input}\n",
    "        \n",
    "        위 의료 기록을 바탕으로 환자의 Brief Hospital Course를 간결하고 명확하게 작성해주세요.\n",
    "        주요 진단, 치료 과정, 경과를 포함하여 작성하세요:\n",
    "        \"\"\"\n",
    "    \n",
    "    async def preprocess_data(self, data: Any) -> str:\n",
    "        \"\"\"의료 기록을 Brief Hospital Course 작성을 위해 전처리\"\"\"\n",
    "        data = data['medical record']\n",
    "        return {'user_input': str(data)}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        \"\"\"결과 정리\"\"\"\n",
    "        result = result.strip()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a8065",
   "metadata": {},
   "source": [
    "# Task B: Radiology Impression 요약\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12648dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskBProcessor(DatathonProcessor):\n",
    "    \"\"\"Task B: Radiology Impression 요약\"\"\"\n",
    "    def get_model_name(self) -> str:\n",
    "        return \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\"\n",
    "    \n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"\n",
    "        당신은 방사선과 전문의입니다. 다음 방사선 검사 보고서를 바탕으로 IMPRESSION을 작성해주세요.\n",
    "        \n",
    "        방사선 검사 보고서:\n",
    "        {user_input}\n",
    "        \n",
    "        위 검사 결과를 바탕으로 의학적으로 정확한 IMPRESSION을 작성해주세요.\n",
    "        주요 소견과 임상적 의미를 포함하여 작성하세요:\n",
    "        \"\"\"\n",
    "    \n",
    "    async def preprocess_data(self, data: Any) -> str:\n",
    "        \"\"\"방사선 보고서를 IMPRESSION 작성을 위해 전처리\"\"\"\n",
    "        data = data['radiology report']\n",
    "        return {'user_input': str(data)}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        \"\"\"결과 정리\"\"\"\n",
    "        result = result.strip()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a3e8a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa61e7",
   "metadata": {},
   "source": [
    "# Task C: ICD 10 코드 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546feac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TaskCProcessor(DatathonProcessor):\n",
    "    \"\"\"Task C: ICD 코드 예측\"\"\"\n",
    "    def get_model_name(self) -> str:\n",
    "        return \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    \n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"\n",
    "        당신은 의료 코딩 전문가입니다. 다음 퇴원 요약을 바탕으로 적절한 ICD 코드를 예측해주세요.\n",
    "        \n",
    "        퇴원 요약:\n",
    "        {user_input}\n",
    "        \n",
    "        위 퇴원 요약을 바탕으로 적절한 ICD 코드를 예측해주세요.\n",
    "        주 진단과 부 진단을 구분하여 작성하세요:\n",
    "        \"\"\"\n",
    "    \n",
    "    async def preprocess_data(self, data: Any) -> str:\n",
    "        \"\"\"퇴원 요약을 ICD 코드 예측을 위해 전처리\"\"\"\n",
    "            data = data['hospital_course']\n",
    "        return {'user_input': str(data)}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        \"\"\"결과 정리\"\"\"\n",
    "        result = result.strip()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349cdb07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d693a",
   "metadata": {},
   "source": [
    "# 1. 데이터 로딩 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277fa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_a_data(data_dir, split=\"test\"):\n",
    "    \"\"\"\n",
    "    Task A 데이터 로드 함수\n",
    "    \"\"\"\n",
    "    if split == \"train\":\n",
    "        file_path = data_dir / \"taskA_train.csv\"\n",
    "    else:\n",
    "        file_path = data_dir / \"taskA_test.csv\"\n",
    "    \n",
    "    if file_path.exists():\n",
    "        print(f\"Task A {split} 데이터 로드 완료: {file_path}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def load_task_b_data(data_dir, split=\"test\"):\n",
    "    \"\"\"\n",
    "    Task B 데이터 로드 함수\n",
    "    \"\"\"\n",
    "    if split == \"train\":\n",
    "        file_path = data_dir / \"taskB_train.csv\"\n",
    "    else:\n",
    "        file_path = data_dir / \"taskB_test.csv\"\n",
    "    \n",
    "    if file_path.exists():\n",
    "        print(f\"Task B {split} 데이터 로드 완료: {file_path}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def load_task_c_data(data_dir, split=\"test\"):\n",
    "    \"\"\"\n",
    "    Task C 데이터 로드 함수  \n",
    "    \"\"\"\n",
    "    if split == \"train\":\n",
    "        file_path = data_dir / \"taskC_train.csv\"\n",
    "    else:\n",
    "        file_path = data_dir / \"taskC_test.csv\"\n",
    "    \n",
    "    if file_path.exists():\n",
    "        print(f\"Task C {split} 데이터 로드 완료: {file_path}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef38bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd1a64",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드 및 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd92a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task A train 데이터 로드 완료: data/taskA_train.csv\n",
      "Task B train 데이터 로드 완료: data/taskB_train.csv\n",
      "Task C train 데이터 로드 완료: data/taskC_train.csv\n",
      "Task A test 데이터 로드 완료: data/taskA_test.csv\n",
      "Task B test 데이터 로드 완료: data/taskB_test.csv\n",
      "Task C test 데이터 로드 완료: data/taskC_test.csv\n"
     ]
    }
   ],
   "source": [
    "# 데이터 디렉토리 경로 설정 (실제 경로로 수정)\n",
    "data_dir = pathlib.Path('./data/')  # 실제 데이터 경로\n",
    "\n",
    "train_data_a = load_task_a_data(data_dir, split=\"train\")[:10]\n",
    "train_data_b = load_task_b_data(data_dir, split=\"train\")[:10]\n",
    "train_data_c = load_task_c_data(data_dir, split=\"train\")[:10]\n",
    "\n",
    "test_data_a = load_task_a_data(data_dir, split=\"test\")[:10]\n",
    "test_data_b = load_task_b_data(data_dir, split=\"test\")[:10]\n",
    "test_data_c = load_task_c_data(data_dir, split=\"test\")[:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d3ed9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffea7ff",
   "metadata": {},
   "source": [
    "## 3. 프로세서 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796d421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 Task별 프로세서 인스턴스 생성\n",
    "task_a = TaskAProcessor(api_key=API_KEY)\n",
    "task_b = TaskBProcessor(api_key=API_KEY)\n",
    "task_c = TaskCProcessor(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbedc7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5083b0",
   "metadata": {},
   "source": [
    "## 4. Task별 프롬프트 예제 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714a041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task별 프롬프트 예제 확인\n",
      "\n",
      "Task A: Brief Hospital Course 작성\n",
      "입력: Medical Record (sample_id: 0)\n",
      "샘플: Name:  ___                  Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   M\n",
      " \n",
      "Serv...\n",
      "출력: Brief Hospital Course (입원경과 요약)\n",
      "\n",
      "Task B: Radiology Impression 요약\n",
      "입력: Radiology Report (sample_id: 0)\n",
      "샘플: EXAMINATION:  C-SPINE NON-TRAUMA ___ VIEWS\n",
      "\n",
      "INDICATION:  ___ year old woman POD#5 LAMINECTOMY FUSION W/INSTRUMENTATION\n",
      "C3-C7 now s/p drain removal// E...\n",
      "출력: IMPRESSION (방사선 소견 요약)\n",
      "\n",
      "Task C: ICD-10 코드 예측\n",
      "입력: Hospital Course (sample_id: 0)\n",
      "샘플: Name:  ___.                  Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Ser...\n",
      "출력: ICD-10 코드들 (예: A01, B02, C03 )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Task별 프롬프트 예제 확인\\n\")\n",
    "\n",
    "# Task A 예제\n",
    "if test_data_a is not None and len(test_data_a) > 0:\n",
    "    sample_data = test_data_a.iloc[0]\n",
    "    print(\"Task A: Brief Hospital Course 작성\")\n",
    "    print(f\"입력: Medical Record (sample_id: {sample_data['sample_id']})\")\n",
    "    print(f\"샘플: {str(sample_data['medical record'])[:150]}...\")\n",
    "    print(\"출력: Brief Hospital Course (입원경과 요약)\\n\")\n",
    "\n",
    "# Task B 예제  \n",
    "if test_data_b is not None and len(test_data_b) > 0:\n",
    "    sample_data = test_data_b.iloc[0]\n",
    "    print(\"Task B: Radiology Impression 요약\")\n",
    "    print(f\"입력: Radiology Report (sample_id: {sample_data['sample_id']})\")\n",
    "    print(f\"샘플: {str(sample_data['radiology report'])[:150]}...\")\n",
    "    print(\"출력: IMPRESSION (방사선 소견 요약)\\n\")\n",
    "\n",
    "# Task C 예제\n",
    "if test_data_c is not None and len(test_data_c) > 0:\n",
    "    sample_data = test_data_c.iloc[0]\n",
    "    print(\"Task C: ICD-10 코드 예측\")\n",
    "    print(f\"입력: Hospital Course (sample_id: {sample_data['sample_id']})\")\n",
    "    print(f\"샘플: {str(sample_data['hospital_course'])[:150]}...\")\n",
    "    print(\"출력: ICD-10 코드들 (예: A01, B02, C03 )\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210acbd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b08f7",
   "metadata": {},
   "source": [
    "## 5. LLM 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7596ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2166.82it/s]\n",
      "100%|██████████| 10/10 [00:19<00:00,  1.92s/it]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14753.09it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 4083.24it/s]\n",
      "100%|██████████| 10/10 [01:17<00:00,  7.71s/it]\n",
      "100%|██████████| 10/10 [00:00<00:00, 17360.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 2433.03it/s]\n",
      "100%|██████████| 10/10 [01:23<00:00,  8.34s/it]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13604.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_task_a_result = await task_a.summarize(train_data_a)\n",
    "train_task_b_result = await task_b.summarize(train_data_b)\n",
    "train_task_c_result = await task_c.summarize(train_data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f830cb2",
   "metadata": {},
   "source": [
    "# 6. validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875bb8d",
   "metadata": {},
   "source": [
    "#### 0. 추가 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad13f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langevaluate.llmtestcase import LLMTestCase\n",
    "from langevaluate.llmdataset import LLMDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b0a34",
   "metadata": {},
   "source": [
    "## 1. Validation 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75132a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "task_categories = ['quality', 'clinical_clarity', 'conciseness', 'hallucination']\n",
    "task_a_test_cases = {category: [] for category in task_categories}\n",
    "\n",
    "for input_text, output_text, expected_output in zip(\n",
    "    train_data_a['medical record'],\n",
    "    train_task_a_result,\n",
    "    train_data_a['target']\n",
    "):\n",
    "    base_case = LLMTestCase(\n",
    "        input=input_text,\n",
    "        output=output_text,\n",
    "        expected_output=expected_output\n",
    "    )\n",
    "    \n",
    "    for category in task_categories:\n",
    "        task_a_test_cases[category].append(copy.deepcopy(base_case))\n",
    "        \n",
    "task_b_test_cases = {category: [] for category in task_categories}\n",
    "\n",
    "for input_text, output_text, expected_output in zip(\n",
    "    train_data_b['radiology report'],\n",
    "    train_task_b_result,\n",
    "    train_data_b['target']\n",
    "):\n",
    "    base_case = LLMTestCase(\n",
    "        input=input_text,\n",
    "        output=output_text,\n",
    "        expected_output=expected_output\n",
    "    )\n",
    "    \n",
    "    for category in task_categories:\n",
    "        task_b_test_cases[category].append(copy.deepcopy(base_case))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d794108",
   "metadata": {},
   "source": [
    "## 1-1 dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "616c9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a_datasets = {category: LLMDataset(test_cases=task_a_test_cases[category]) for category in task_categories}\n",
    "task_b_datasets = {category: LLMDataset(test_cases=task_b_test_cases[category]) for category in task_categories}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba79115",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128e366",
   "metadata": {},
   "source": [
    "## 2. LLM 채점용 template 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2619a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langevaluate.metrics.summary_judge.summary_judge_metric import SummaryJudgeMetric\n",
    "from langevaluate.metrics.summary_judge.summary_judge_template import SummaryJudgeTemplate\n",
    "\n",
    "task_a_quality = SummaryJudgeMetric(\n",
    "    score_model=validation_llm,\n",
    "    category='brief_hospital_course_quality',\n",
    "    template_language='en',  # 'ko' 또는 'en'\n",
    "    generate_template_type='reasoning'  # 'reasoning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19ddde9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<role>Evaluate the quality of the AI assistant’s brief hospital course of the clinical history shown below.</role>\n",
      "\n",
      "<task>\n",
      "Provide your reasoning and score with only the integer (0, 1, 2, 3, 4, 5).\n",
      "\n",
      "Evaluation Rubric (compare the generated brief hospital course against BOTH the clinical history and the expected brief hospital course):\n",
      "Question: The brief hospital course is irrelevant to the clinical history or fails to address the question.\n",
      "\n",
      "5 : The brief hospital course is excellent — it captures all the key points clearly, concisely, and naturally.\n",
      "4 : The brief hospital course is good — it conveys most of the key information, but may miss some nuance or clarity.\n",
      "3 : The brief hospital course is fair — it includes some important points but omits or distorts others, leading to partial understanding.\n",
      "2 : The brief hospital course is weak — it captures only a small portion of the original meaning, or is vague and confusing.\n",
      "1 : The brief hospital course is poor — it barely addresses the content, with little relevance or coherence.\n",
      "0 : The brief hospital course is irrelevant to the clinical history.\n",
      "\n",
      "**IMPORTANT**: Please make sure to only return in JSON format, with the 'reasoning' key providing the reasoning.\n",
      "Example JSON:\n",
      "{{    \n",
      "    \"reasoning\": \"<your_reasoning. Think step by step deeply.>. So the score is <your_score>\",\n",
      "    \"score\": \"<your_score>\"\n",
      "}}\n",
      "</task>\n",
      "\n",
      "<clinical_history>\n",
      "{clinical_history}\n",
      "</clinical_history>\n",
      "\n",
      "<expected_brief_hospital_course>\n",
      "{expected_summary}\n",
      "</expected_brief_hospital_course>\n",
      "\n",
      "<generated_brief_hospital_course>\n",
      "{summary}\n",
      "</generated_brief_hospital_course>\n",
      "\n",
      "JSON:\n"
     ]
    }
   ],
   "source": [
    "# llm 채점용 template\n",
    "print(metric_summarization_quality.template_for_judge.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc9394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a_metrics = {}\n",
    "task_a_metrics = {i : SummaryJudgeMetric(score_model=validation_llm, \n",
    "                                         category=f'brief_hospital_course_{i}', \n",
    "                                         template_language='en', \n",
    "                                         generate_template_type='reasoning') for i in task_categories}\n",
    "task_b_metrics = {i : SummaryJudgeMetric(score_model=validation_llm, \n",
    "                                         category=f'radiology_impression_{i}', \n",
    "                                         template_language='en', \n",
    "                                         generate_template_type='reasoning') for i in task_categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfa37467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langevaluate.metrics.summary_judge.summary_judge_metric.SummaryJudgeMetric at 0x177424940>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_a_metrics['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd1f34",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf80b9c",
   "metadata": {},
   "source": [
    "## 3. 평가 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await task_a_metrics['quality'].ameasure(datasets['summarization_quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93394434",
   "metadata": {},
   "source": [
    "### 평균 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sum([int(i.score) for i in result]) / len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6f2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b63d4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6ef23",
   "metadata": {},
   "source": [
    "## 4. BertScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d51f5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [18:37<?, ?it/s]\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-227' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-228' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-229' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-230' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-231' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-232' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-233' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-234' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-235' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object dict can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jin/Desktop/코딩/recent/MARS_challenge_2025/example/data_dummy/datathon/.venv/lib/python3.10/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "TypeError: object dict can't be used in 'await' expression\n",
      " 40%|████      | 4/10 [03:16<04:54, 49.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore F1 결과: [0.9206523299217224, 0.9264420866966248]\n",
      "평균 BertScore: 0.9235\n"
     ]
    }
   ],
   "source": [
    "from langevaluate.quantiative_metrics import BertScore\n",
    "\n",
    "# BertScore 인스턴스 생성\n",
    "bertscore_metric = BertScore(model_type=\"distilbert-base-uncased\", batch_size=16)\n",
    "\n",
    "# 테스트 데이터\n",
    "test_hyps = [\n",
    "    'Patient was admitted with chest pain and treated successfully.',\n",
    "    'The radiology report shows normal findings.'\n",
    "]\n",
    "\n",
    "test_refs = [\n",
    "    'Patient admitted for chest pain, treatment was effective.',\n",
    "    'Radiology report indicates normal results.'\n",
    "]\n",
    "\n",
    "# BertScore 계산 (올바른 방법)\n",
    "bert_scores = bertscore_metric(refs=test_refs, hyps=test_hyps)\n",
    "print(f\"BertScore F1 결과: {bert_scores}\")\n",
    "print(f\"평균 BertScore: {sum(bert_scores)/len(bert_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc493c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 BertScore: 0.7053\n"
     ]
    }
   ],
   "source": [
    "# Task B BertScore 계산\n",
    "submission_b_train = pd.read_csv('./result/submission_taskB_train.csv')\n",
    "# 예측값과 정답 추출\n",
    "predictions = submission_b_train['target'].astype(str).tolist()\n",
    "references = train_data_b['target'].astype(str).tolist()\n",
    "\n",
    "# BertScore 계산\n",
    "bert_scores_task_b = bertscore_metric(refs=references, hyps=predictions)\n",
    "avg_bert_score_b = sum(bert_scores_task_b) / len(bert_scores_task_b)\n",
    "\n",
    "print(f\"평균 BertScore: {avg_bert_score_b:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320dd30e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51dcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>dod</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>...</th>\n",
       "      <th>dbp</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pain</th>\n",
       "      <th>transfer_id</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>careunit</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2189</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2189-12-23</td>\n",
       "      <td>2189-12-18 12:58:00</td>\n",
       "      <td>2189-12-21 12:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>2</td>\n",
       "      <td>33399871</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med/Surg</td>\n",
       "      <td>2189-12-18 15:26:00</td>\n",
       "      <td>2189-12-21 12:50:35</td>\n",
       "      <td>___ year old man with with PMH of cirrhosis, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>91</td>\n",
       "      <td>2150</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2150-05-10 20:02:00</td>\n",
       "      <td>2150-05-13 16:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>0</td>\n",
       "      <td>31444432</td>\n",
       "      <td>transfer</td>\n",
       "      <td>Med/Surg</td>\n",
       "      <td>2150-05-11 22:24:12</td>\n",
       "      <td>2150-05-12 06:29:25</td>\n",
       "      <td>___ with a PMH of severe Alzheimer's, HCV infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>91</td>\n",
       "      <td>2121</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>2121-03-24</td>\n",
       "      <td>2121-03-16 16:25:00</td>\n",
       "      <td>2121-03-20 17:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32510227</td>\n",
       "      <td>ED</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>2121-03-16 11:36:00</td>\n",
       "      <td>2121-03-16 17:53:00</td>\n",
       "      <td>TRANSITIONAL ISSUES \\n==================== \\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>2117</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>2126-11-20</td>\n",
       "      <td>2121-05-23 18:54:00</td>\n",
       "      <td>2121-05-27 12:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>102.7</td>\n",
       "      <td>9</td>\n",
       "      <td>33869192</td>\n",
       "      <td>admit</td>\n",
       "      <td>Transplant</td>\n",
       "      <td>2121-05-23 21:00:00</td>\n",
       "      <td>2121-05-24 10:26:24</td>\n",
       "      <td>Mr. ___ is a ___ year old man with history of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>82</td>\n",
       "      <td>2131</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>2131-10-03</td>\n",
       "      <td>2131-08-25 23:59:00</td>\n",
       "      <td>2131-09-04 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>97.6</td>\n",
       "      <td>10</td>\n",
       "      <td>34923982</td>\n",
       "      <td>admit</td>\n",
       "      <td>Neuro Intermediate</td>\n",
       "      <td>2131-08-26 00:43:00</td>\n",
       "      <td>2131-08-27 11:36:02</td>\n",
       "      <td>SUMMARY\\n============\\n___ is a ___ year old f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id gender  anchor_age  anchor_year anchor_year_group         dod  \\\n",
       "0          0      M          66         2189       2014 - 2016  2189-12-23   \n",
       "1          1      F          91         2150       2014 - 2016         NaN   \n",
       "2          2      M          91         2121       2017 - 2019  2121-03-24   \n",
       "3          3      M          59         2117       2011 - 2013  2126-11-20   \n",
       "4          4      F          82         2131       2017 - 2019  2131-10-03   \n",
       "\n",
       "             admittime            dischtime deathtime     admission_type  ...  \\\n",
       "0  2189-12-18 12:58:00  2189-12-21 12:50:00       NaN             URGENT  ...   \n",
       "1  2150-05-10 20:02:00  2150-05-13 16:40:00       NaN           EW EMER.  ...   \n",
       "2  2121-03-16 16:25:00  2121-03-20 17:52:00       NaN  OBSERVATION ADMIT  ...   \n",
       "3  2121-05-23 18:54:00  2121-05-27 12:45:00       NaN  OBSERVATION ADMIT  ...   \n",
       "4  2131-08-25 23:59:00  2131-09-04 15:30:00       NaN  OBSERVATION ADMIT  ...   \n",
       "\n",
       "     dbp    sbp  temperature pain transfer_id  eventtype  \\\n",
       "0   58.0   94.0         98.5    2    33399871      admit   \n",
       "1   55.0  145.0         98.9    0    31444432   transfer   \n",
       "2   79.0  154.0         98.0    2    32510227         ED   \n",
       "3  104.0  151.0        102.7    9    33869192      admit   \n",
       "4   56.0  152.0         97.6   10    34923982      admit   \n",
       "\n",
       "               careunit               intime              outtime  \\\n",
       "0              Med/Surg  2189-12-18 15:26:00  2189-12-21 12:50:35   \n",
       "1              Med/Surg  2150-05-11 22:24:12  2150-05-12 06:29:25   \n",
       "2  Emergency Department  2121-03-16 11:36:00  2121-03-16 17:53:00   \n",
       "3            Transplant  2121-05-23 21:00:00  2121-05-24 10:26:24   \n",
       "4    Neuro Intermediate  2131-08-26 00:43:00  2131-08-27 11:36:02   \n",
       "\n",
       "                                              target  \n",
       "0  ___ year old man with with PMH of cirrhosis, H...  \n",
       "1  ___ with a PMH of severe Alzheimer's, HCV infe...  \n",
       "2  TRANSITIONAL ISSUES \\n==================== \\nD...  \n",
       "3  Mr. ___ is a ___ year old man with history of ...  \n",
       "4  SUMMARY\\n============\\n___ is a ___ year old f...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f8c94",
   "metadata": {},
   "source": [
    "## 5. ICDScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eefb6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langevaluate.quantiative_metrics import ICDScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3236b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 F1 Score: 0.0700\n"
     ]
    }
   ],
   "source": [
    "# Task C ICD Score 계산 \n",
    "submission_c_train = pd.read_csv('./result/submission_taskC_train.csv')\n",
    "\n",
    "# 예측값과 정답 추출 및 전처리\n",
    "def parse_icd_codes(codes_str):\n",
    "    \"\"\"ICD 코드 문자열을 리스트로 변환\"\"\"\n",
    "    if pd.isna(codes_str):\n",
    "        return []\n",
    "    return [code.strip() for code in str(codes_str).split(',') if code.strip()]\n",
    "\n",
    "predictions_icd = submission_c_train['target'].apply(parse_icd_codes).tolist()\n",
    "references_icd = train_data_c['target'].apply(parse_icd_codes).tolist()\n",
    "\n",
    "\n",
    "icd_scores = ICDScore()(predictions_icd, references_icd)\n",
    "avg_icd_score = sum(icd_scores) / len(icd_scores) if icd_scores else 0\n",
    "\n",
    "print(f\"평균 F1 Score: {avg_icd_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2efe9c8",
   "metadata": {},
   "source": [
    "## 6. 공정성 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eda09c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langevaluate.quantiative_metrics import FairnessScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_score = FairnessScore()\n",
    "genders = train_data_b['gender']\n",
    "age = train_data_b['anchor_age']\n",
    "sex_fairness_score = fairness_score(genders, bert_scores_task_b, type='sex')\n",
    "age_fairness_score = fairness_score(age, bert_scores_task_b, type='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('성별 공정성 지표 : ', sex_fairness_score)\n",
    "print('나이 공정성 지표 : ', age_fairness_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
