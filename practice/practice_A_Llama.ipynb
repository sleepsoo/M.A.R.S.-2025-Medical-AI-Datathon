{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc941d4",
   "metadata": {},
   "source": [
    "## taskA Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ec5128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/datathon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from typing import Any, List, Dict\n",
    "from typing import Optional, Dict, Any, List, Union\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain.prompts import ChatPromptTemplate  # 프롬프트 템플릿 처리용\n",
    "from langevaluate.config import ModelConfig # LLM 설정용\n",
    "from langevaluate.llmfactory import LLMFactory  # LLM 팩토리용\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import asyncio\n",
    "\n",
    "class DatathonProcessor(ABC):\n",
    "    \"\"\"\n",
    "    데이터톤용 AI 처리 통합 클래스\n",
    "    쿼리, 평가, 임베딩을 일괄 처리할 수 있습니다.\n",
    "    사용자는 이 클래스를 상속받아 특정 메서드만 구현하면 됩니다.\n",
    "    \"\"\"\n",
    "    # LLM 설정 상수들\n",
    "    \n",
    "    DEFAULT_MODEL_CONFIG = {\n",
    "        'model_name': 'LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ',\n",
    "        'api_base': 'https://api.snubhai.org/api/v1/llm',\n",
    "        'max_tokens': 2000,\n",
    "        'seed': 777,\n",
    "        'temperature': 0,\n",
    "        'rpm': 10\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key : str,\n",
    "    ):\n",
    "        # 기본 설정 복사\n",
    "        config = self.DEFAULT_MODEL_CONFIG.copy()\n",
    "        \n",
    "        # model_name만 클래스별 설정으로 업데이트\n",
    "        config['model_name'] = self.get_model_name()\n",
    "        \n",
    "        # LLM 설정 생성\n",
    "        custom_config = ModelConfig(\n",
    "            model_name=config['model_name'],\n",
    "            api_base=config['api_base'],\n",
    "            api_key=api_key,\n",
    "            max_tokens=config['max_tokens'],\n",
    "            seed=config['seed'],\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        # LLM 인스턴스 생성\n",
    "        self.llm = LLMFactory.create_llm(\n",
    "            custom_config, \n",
    "            temperature=config['temperature'], \n",
    "            rpm=config['rpm']\n",
    "        )\n",
    "        \n",
    "        # 프롬프트 템플릿 설정\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "        # 결과 저장소\n",
    "        self.results: List[str] = []\n",
    "        \n",
    "        # metric 저장소\n",
    "        self.metrics: Dict[str, Any] = {}\n",
    "    \n",
    "        \n",
    "    def get_model_name(self) -> str:\n",
    "        \"\"\"\n",
    "        사용할 모델명을 반환합니다.\n",
    "        상속 클래스에서 이 메서드를 오버라이드하여 특정 모델을 설정할 수 있습니다.\n",
    "        \"\"\"\n",
    "        return self.DEFAULT_MODEL_CONFIG['model_name']\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    async def preprocess_data(self, data: Any) -> Dict[str, Any]:\n",
    "        \"\"\"데이터 전처리 메서드\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_prompt_template(self) -> str:\n",
    "        \"\"\"사용자가 구현해야 하는 프롬프트 템플릿 메서드\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def postprocess_result(self, result: Any) -> str:\n",
    "        \"\"\"데이터 후처리 메서드\"\"\"\n",
    "        pass\n",
    "\n",
    "    async def summarize(\n",
    "        self, \n",
    "        data: pd.DataFrame\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        단일 입력과 배치 입력을 모두 처리하는 통합 메서드\n",
    "        \"\"\"\n",
    "        # 데이터 전처리\n",
    "        \n",
    "        preprocess_tasks = [self.preprocess_data(row) for _, row in data.iterrows()]\n",
    "        preprocessed_data = await tqdm_asyncio.gather(*preprocess_tasks)\n",
    "\n",
    "        # 각각을 별도의 coroutine으로 실행\n",
    "        tasks = [self.chain.ainvoke(vars) for vars in preprocessed_data]\n",
    "\n",
    "        # tqdm_asyncio.gather로 동시에 실행하며 progress bar 표시\n",
    "        responses = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "        postprocess_tasks = [self.postprocess_result(r.content) for r in responses]\n",
    "        results = await tqdm_asyncio.gather(*postprocess_tasks)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbbcc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🏆 Task A 리더보드 정확 평가 시뮬레이션\n",
      "================================================================================\n",
      "1. 데이터 로드 중...\n",
      "평가 샘플: 300개\n",
      "\n",
      "📊 데이터 분포:\n",
      "성별: {'M': 155, 'F': 145}\n",
      "연령: 평균 63.4세\n",
      "\n",
      "2. TaskA 처리기 초기화 (EXAONE 모델)...\n",
      "3. Brief Hospital Course 생성 중...\n",
      "   배치 1/38 처리 중...\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 2/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 3/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 4/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 5/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 6/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 7/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 8/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 9/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 10/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 11/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 12/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 13/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 14/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 15/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 16/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 17/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 18/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 19/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 20/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 21/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 22/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 23/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 24/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 25/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 26/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 27/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 28/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 29/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 30/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 31/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 32/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 33/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 34/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 35/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 36/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 37/38 처리 중...\n",
      "   API 제한 준수를 위해 70초 대기...\n",
      "   배치 38/38 처리 중...\n",
      "예측 생성 완료 (총 소요 시간: 5064.9초)\n",
      "\n",
      "4. BERTScore 계산 중...\n",
      "5. 공정성 지표 계산 중...\n",
      "\n",
      "================================================================================\n",
      "🎯 Task A 리더보드 정확 평가 결과\n",
      "================================================================================\n",
      "📊 BERTScore (대회 공식 계산)\n",
      "   평균: 0.771005\n",
      "   표준편차: 0.020697\n",
      "   최고: 0.813723\n",
      "   최저: 0.684786\n",
      "   중앙값: 0.773139\n",
      "\n",
      "⚖️ 공정성 지표 (대회 공식 계산)\n",
      "   성별 공정성: 0.994164\n",
      "   성별별 성능: {'F': 0.7733365387752138, 'M': 0.7688233417849387}\n",
      "   성별 격차: 0.004513\n",
      "   \n",
      "   연령 공정성: 0.977805\n",
      "   연령대별 성능: {'10-20': 0.766829252243042, '20-30': 0.7700861061320585, '30-40': 0.778713047504425, '40-50': 0.7758198868144642, '50-60': 0.7715244720379512, '60-70': 0.7722391301477459, '70-80': 0.7731823652398353, '80-90': 0.7614295316296954, '90-100': 0.7700086385011673}\n",
      "   연령 격차: 0.017284\n",
      "\n",
      "🏆 Task A 정량 평가 점수\n",
      "   BERTScore: 9.071/10.000 점\n",
      "   공정성 지표: 6.000/6.000 점\n",
      "   정량 총점: 15.071/16.000 점\n",
      "   정량 달성률: 94.2%\n",
      "\n",
      "🎖️ 성능 등급\n",
      "   등급: S급 (최우수)\n",
      "   권장사항: 즉시 제출 권장\n",
      "\n",
      "📝 예측 품질 샘플 (상위/하위 각 3개)\n",
      "--------------------------------------------------------------------------------\n",
      "🏆 최고 성능 샘플:\n",
      "샘플 169 (BERTScore: 0.8137)\n",
      "예측: Ms. ___, a 35-year-old female, was admitted to the Neurosurgery service with a chief complaint of unsteady gait and a history of a recent syncopal event. She underwent a routine outpatient head MRI fo...\n",
      "정답: Mrs. ___ was admitted to the ___ Neurosurgery service \n",
      "for management of her left subdural hematoma.  She underwent \n",
      "work-up for her questionable syncopal epside.  An echocardiogram \n",
      "showed normal biv...\n",
      "\n",
      "샘플 72 (BERTScore: 0.8124)\n",
      "예측: Ms. ___ was admitted to the Neurosurgery service with a chief complaint of a right subdural hematoma with midline shift. She was a  [REDACTED] year-old female with a significant past medical history o...\n",
      "정답: Mrs. ___ was admitted to the Neurosurgery service on ___ \n",
      "for further management and observation after suffering a fall \n",
      "resulting a left acute on chronic subdural hematoma.  As she was \n",
      "intubated for...\n",
      "\n",
      "샘플 187 (BERTScore: 0.8110)\n",
      "예측: Mr. [REDACTED], a 65-year-old male with a history of Type A aortic dissection and aortic valve replacement (AVR), was admitted to the medicine service for evaluation of headaches and fevers. \n",
      "\n",
      "**Admis...\n",
      "정답: Mr. ___ is a ___ YO male with a history of AVR ___ \n",
      "___ ___ replacement after Type A aortic dissection, who \n",
      "presented as an OSH transfer due to concern for meningitis. \n",
      "Work-up revealed anaplasmosis ...\n",
      "\n",
      "⚠️ 최저 성능 샘플:\n",
      "샘플 125 (BERTScore: 0.6848)\n",
      "예측: Mr. [REDACTED] was admitted to the medicine service with a chief complaint of nausea and vomiting. His past medical history is notable for hypertension, benign prostatic hyperplasia (BPH), and a histo...\n",
      "정답: Mr. ___ is a lovely ___ year old man with hypertension & history \n",
      "of carotid stenosis who presented with nausea & vomiting x3 \n",
      "days. \n",
      "\n",
      "================...\n",
      "\n",
      "샘플 127 (BERTScore: 0.7049)\n",
      "예측: Mr. [REDACTED] was admitted to the medicine service for evaluation and management of symptomatic bradycardia. He presented with a chief complaint of intermittent episodes of dizziness and lightheadedn...\n",
      "정답: =======================\n",
      "SUMMARY STATEMENT\n",
      "=======================\n",
      "\n",
      "Mr ___ is a ___ y/o M with PMH significant for rheumatic heart\n",
      "disease who presented with several weeks of lightheadedness and \n",
      "brady...\n",
      "\n",
      "샘플 39 (BERTScore: 0.7075)\n",
      "예측: Ms. ___ was admitted to the medicine service for management of a percutaneously placed cholecystostomy tube and evaluation of bilateral pleural effusions. She presented with a history of recurrent cho...\n",
      "정답: Discharge Worksheet - Key Information for Outpatient \n",
      "___, MD on ___ @ 1608 ...\n",
      "\n",
      "\n",
      "🎉 Task A 리더보드 평가 완료!\n",
      "최종 예상 점수: 15.071/16.000 점\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import asyncio\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "from bert_score import BERTScorer\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langevaluate.config import ModelConfig\n",
    "from langevaluate.llmfactory import LLMFactory\n",
    "import re\n",
    "\n",
    "# 대회 제공 BertScore 클래스 (100% 동일)\n",
    "class BertScore:\n",
    "    def __init__(self, model_type=\"distilbert-base-uncased\", batch_size=16):\n",
    "        with torch.no_grad():\n",
    "            self.bert_scorer = BERTScorer(\n",
    "                model_type=model_type,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "\n",
    "    def __call__(self, refs, hyps):\n",
    "        p, r, f = self.bert_scorer.score(\n",
    "            cands=hyps,\n",
    "            refs=refs,\n",
    "            verbose=False,\n",
    "            batch_size=8,\n",
    "        )\n",
    "        return f.tolist()\n",
    "\n",
    "# 대회 제공 FairnessScore 클래스 (100% 동일)\n",
    "class FairnessScore:\n",
    "    def __init__(self, bin_width: int = 10, min_samples_per_group: int = 1):\n",
    "        self.bin_width = int(bin_width)\n",
    "        self.min_samples_per_group = int(min_samples_per_group)\n",
    "        self.last_stats = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_1d(a) -> np.ndarray:\n",
    "        a = np.asarray(a)\n",
    "        if a.ndim == 2 and a.shape[1] == 1:\n",
    "            a = a[:, 0]\n",
    "        if a.ndim != 1:\n",
    "            raise ValueError(\"Input must be 1D or (N,1) shaped.\")\n",
    "        return a\n",
    "\n",
    "    def _bin_ages(self, ages) -> np.ndarray:\n",
    "        a = self._ensure_1d(ages).astype(float)\n",
    "        if np.any(np.isnan(a)):\n",
    "            raise ValueError(\"ages contain NaN.\")\n",
    "        if self.bin_width <= 0:\n",
    "            raise ValueError(\"bin_width must be positive.\")\n",
    "        starts = (np.floor(a / self.bin_width) * self.bin_width).astype(int)\n",
    "        ends = starts + self.bin_width\n",
    "        labels = np.array([f\"{s:d}-{e:d}\" for s, e in zip(starts, ends)], dtype=object)\n",
    "        return labels\n",
    "\n",
    "    def _groups_from_type(self, groups, type: str) -> np.ndarray:\n",
    "        t = (type or \"sex\").lower()\n",
    "        if t not in (\"sex\", \"age\"):\n",
    "            raise ValueError(\"type must be 'sex' or 'age'.\")\n",
    "        if t == \"sex\":\n",
    "            g = self._ensure_1d(groups)\n",
    "            return g\n",
    "        else:\n",
    "            return self._bin_ages(groups)\n",
    "\n",
    "    def __call__(self, groups, scores, type: str = \"sex\", sample_weight=None) -> float:\n",
    "        g = self._groups_from_type(groups, type=type)\n",
    "        s = self._ensure_1d(scores).astype(float)\n",
    "        if s.shape[0] != g.shape[0]:\n",
    "            raise ValueError(\"groups and scores must have the same length.\")\n",
    "\n",
    "        if sample_weight is None:\n",
    "            w = np.ones_like(s, dtype=float)\n",
    "        else:\n",
    "            w = self._ensure_1d(sample_weight).astype(float)\n",
    "            if w.shape[0] != s.shape[0]:\n",
    "                raise ValueError(\"sample_weight length must match scores.\")\n",
    "\n",
    "        s = np.clip(s, 0.0, 1.0)\n",
    "\n",
    "        uniq = np.unique(g)\n",
    "        means = []\n",
    "        by_group = {}\n",
    "        for grp in uniq:\n",
    "            mask = (g == grp)\n",
    "            if np.sum(mask) < self.min_samples_per_group:\n",
    "                continue\n",
    "            denom = np.sum(w[mask])\n",
    "            if denom <= 0:\n",
    "                continue\n",
    "            m = float(np.average(s[mask], weights=w[mask]))\n",
    "            means.append(m)\n",
    "            by_group[str(grp)] = m\n",
    "\n",
    "        if len(means) <= 1:\n",
    "            self.last_stats = {\"by_group\": by_group, \"gap\": 0.0, \"min\": None, \"max\": None}\n",
    "            return 1.0\n",
    "\n",
    "        max_m = float(np.max(means))\n",
    "        min_m = float(np.min(means))\n",
    "        fairness = 1.0 if max_m == 0.0 else float(min_m / max_m)\n",
    "        fairness = float(np.clip(fairness, 0.0, 1.0))\n",
    "\n",
    "        self.last_stats = {\"by_group\": by_group, \"gap\": max_m - min_m, \"min\": min_m, \"max\": max_m}\n",
    "        return fairness\n",
    "\n",
    "# TaskA Processor (앞서 작성한 최적화 버전)\n",
    "class TaskAProcessor:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        \n",
    "        config = ModelConfig(\n",
    "            # model_name=\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\",\n",
    "            model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "            api_base=\"https://api.snubhai.org/api/v1/llm\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=1500,\n",
    "            seed=777,\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        self.llm = LLMFactory.create_llm(config, temperature=0, rpm=10)\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"You are a senior attending physician with 15+ years of experience writing comprehensive Brief Hospital Course summaries. Create a professional, chronologically structured summary that captures the essential medical narrative.\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Write 250-400 words (optimal length based on successful cases)\n",
    "- Maintain chronological flow: Admission → Course → Outcome\n",
    "- Use precise medical terminology consistently\n",
    "- Include key diagnostic findings, treatments, and patient responses\n",
    "- Maintain professional tone regardless of patient demographics\n",
    "- Focus on clinically significant events and interventions\n",
    "\n",
    "STRUCTURE METHODOLOGY:\n",
    "1. Opening: Patient presentation and admission reason\n",
    "2. Initial Assessment: Key findings, diagnostics, initial diagnosis\n",
    "3. Hospital Course: Chronological treatment progression, complications\n",
    "4. Clinical Response: Patient improvement/deterioration, interventions\n",
    "5. Discharge Planning: Final status, disposition, follow-up needs\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "MEDICAL RECORD: [Complex gynecologic oncology case...]\n",
    "BRIEF HOSPITAL COURSE: Ms. ___ was admitted to the gynecologic oncology service after undergoing diagnostic laparoscopy converted to exploratory laparotomy, total abdominal hysterectomy, bilateral salpingo-oophrectomy, omentectomy, pelvic and para-aortic lymph node dissection, and tumor debulking for Stage IIIC ovarian carcinoma. Her postoperative course was complicated by prolonged ileus requiring nasogastric decompression and total parenteral nutrition. She developed a wound infection on postoperative day 5 treated with antibiotics and wound care. Patient was discharged home on postoperative day 8 in stable condition with visiting nurse services arranged.\n",
    "\n",
    "MEDICAL RECORD: [Cardiac case with preoperative evaluation...]\n",
    "BRIEF HOSPITAL COURSE: He was admitted to the cardiology service and remained chest pain free. He underwent routine preoperative testing and evaluation. He developed early signs of gout flare in the right and left hallux which was treated with colchicine and responded well. His cardiac catheterization revealed severe three-vessel coronary artery disease requiring surgical revascularization. He was medically optimized and discharged home after 3 days in stable condition with cardiothoracic surgery follow-up scheduled.\n",
    "\n",
    "Now create a Brief Hospital Course for:\n",
    "\n",
    "MEDICAL RECORD: {user_input}\n",
    "\n",
    "BRIEF HOSPITAL COURSE:\"\"\"\n",
    "\n",
    "    async def preprocess_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        medical_record = data['medical record']\n",
    "        \n",
    "        if pd.isna(medical_record) or not isinstance(medical_record, str):\n",
    "            return {'user_input': ''}\n",
    "        \n",
    "        processed_sections = []\n",
    "        \n",
    "        # Chief Complaint & Service\n",
    "        if 'Chief Complaint:' in medical_record:\n",
    "            cc_match = re.search(r'Chief Complaint:\\s*([^\\n]+)', medical_record)\n",
    "            if cc_match:\n",
    "                processed_sections.append(f\"Chief Complaint: {cc_match.group(1).strip()}\")\n",
    "        \n",
    "        if 'Service:' in medical_record:\n",
    "            service_match = re.search(r'Service:\\s*([^\\n]+)', medical_record)\n",
    "            if service_match:\n",
    "                processed_sections.append(f\"Service: {service_match.group(1).strip()}\")\n",
    "        \n",
    "        # History of Present Illness\n",
    "        if 'History of Present Illness:' in medical_record:\n",
    "            hpi_match = re.search(r'History of Present Illness:\\s*(.*?)(?=\\n\\n|\\nPast Medical|Physical Exam|$)', \n",
    "                                medical_record, re.DOTALL)\n",
    "            if hpi_match:\n",
    "                hpi = hpi_match.group(1).strip()[:800]\n",
    "                processed_sections.append(f\"History: {hpi}\")\n",
    "        \n",
    "        # Major Procedures\n",
    "        if 'Major Surgical or Invasive Procedure:' in medical_record:\n",
    "            proc_match = re.search(r'Major Surgical or Invasive Procedure:\\s*(.*?)(?=\\n\\n|History of Present|$)', \n",
    "                                 medical_record, re.DOTALL)\n",
    "            if proc_match:\n",
    "                proc = proc_match.group(1).strip()\n",
    "                if proc.lower() not in ['none', 'none.']:\n",
    "                    processed_sections.append(f\"Major Procedures: {proc}\")\n",
    "        \n",
    "        # Past Medical History\n",
    "        if 'Past Medical History:' in medical_record:\n",
    "            pmh_match = re.search(r'Past Medical History:\\s*(.*?)(?=\\n\\n|PAST SURGICAL|Social History|$)',\n",
    "                                medical_record, re.DOTALL)\n",
    "            if pmh_match:\n",
    "                pmh = pmh_match.group(1).strip()[:400]\n",
    "                processed_sections.append(f\"Past Medical History: {pmh}\")\n",
    "        \n",
    "        # Imaging IMPRESSION\n",
    "        impressions = re.findall(r'IMPRESSION:\\s*(.*?)(?=\\n\\n|\\n[A-Z_]|\\Z)', medical_record, re.DOTALL)\n",
    "        if impressions:\n",
    "            for i, imp in enumerate(impressions[:2]):\n",
    "                processed_sections.append(f\"Imaging {i+1}: {imp.strip()[:200]}\")\n",
    "        \n",
    "        processed_text = '\\n\\n'.join(processed_sections)\n",
    "        processed_text = re.sub(r'___+', '[REDACTED]', processed_text)\n",
    "        processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
    "        processed_text = processed_text[:3000]\n",
    "        \n",
    "        return {'user_input': processed_text.strip()}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        result = result.strip()\n",
    "        \n",
    "        prefixes = ['BRIEF HOSPITAL COURSE:', 'Brief Hospital Course:', 'brief hospital course:']\n",
    "        for prefix in prefixes:\n",
    "            if result.startswith(prefix):\n",
    "                result = result[len(prefix):].strip()\n",
    "        \n",
    "        if result and not result.endswith('.'):\n",
    "            result += '.'\n",
    "        \n",
    "        # 단어 수 최적화\n",
    "        words = result.split()\n",
    "        if len(words) > 450:\n",
    "            sentences = [s.strip() for s in result.split('.') if s.strip()]\n",
    "            important_keywords = ['admitted', 'diagnosis', 'treated', 'underwent', 'developed', \n",
    "                                'improved', 'discharged', 'course', 'complication']\n",
    "            \n",
    "            important_sentences = []\n",
    "            for sentence in sentences:\n",
    "                if any(keyword in sentence.lower() for keyword in important_keywords) or len(important_sentences) < 3:\n",
    "                    important_sentences.append(sentence.strip())\n",
    "                if len(' '.join(important_sentences).split()) >= 400:\n",
    "                    break\n",
    "            \n",
    "            if important_sentences:\n",
    "                result = '. '.join(important_sentences)\n",
    "                if not result.endswith('.'):\n",
    "                    result += '.'\n",
    "        \n",
    "        # 의료 용어 표준화\n",
    "        medical_corrections = {\n",
    "            'pt ': 'patient ',\n",
    "            'w/ ': 'with ',\n",
    "            'w/o ': 'without ',\n",
    "            'h/o ': 'history of '\n",
    "        }\n",
    "        \n",
    "        for wrong, correct in medical_corrections.items():\n",
    "            result = result.replace(wrong, correct)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# 리더보드 100% 동일 평가 함수\n",
    "async def exact_taskA_evaluation(train_csv_path: str, api_key: str):\n",
    "    \"\"\"대회 리더보드와 정확히 동일한 Task A 평가\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"🏆 Task A 리더보드 정확 평가 시뮬레이션\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. 데이터 로드 및 전처리\n",
    "    print(\"1. 데이터 로드 중...\")\n",
    "    df = pd.read_csv(train_csv_path)\n",
    "    df = df.dropna(subset=['medical record', 'target'])\n",
    "    \n",
    "    eval_samples = min(300, len(df))\n",
    "    eval_df = df.iloc[:eval_samples].copy()\n",
    "    print(f\"평가 샘플: {eval_samples}개\")\n",
    "    \n",
    "    print(f\"\\n📊 데이터 분포:\")\n",
    "    print(f\"성별: {eval_df['gender'].value_counts().to_dict()}\")\n",
    "    print(f\"연령: 평균 {eval_df['anchor_age'].mean():.1f}세\")\n",
    "    \n",
    "    # 2. TaskA 처리기 초기화\n",
    "    print(\"\\n2. TaskA 처리기 초기화 (EXAONE 모델)...\")\n",
    "    processor = TaskAProcessor(api_key)\n",
    "    \n",
    "    # 3. 예측 생성\n",
    "    print(\"3. Brief Hospital Course 생성 중...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    data_batch = [{'medical record': row['medical record']} for _, row in eval_df.iterrows()]\n",
    "    \n",
    "    results = []\n",
    "    batch_size = 8\n",
    "    \n",
    "    for i in range(0, len(data_batch), batch_size):\n",
    "        batch = data_batch[i:i+batch_size]\n",
    "        print(f\"   배치 {i//batch_size + 1}/{(len(data_batch)-1)//batch_size + 1} 처리 중...\")\n",
    "        \n",
    "        # 전처리\n",
    "        preprocessed = [await processor.preprocess_data(row) for row in batch]\n",
    "        \n",
    "        # API 호출\n",
    "        tasks = [processor.chain.ainvoke(prep) for prep in preprocessed]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # 후처리\n",
    "        batch_results = [await processor.postprocess_result(r.content) for r in responses]\n",
    "        results.extend(batch_results)\n",
    "        \n",
    "        # API 제한 준수\n",
    "        if i + batch_size < len(data_batch):\n",
    "            print(f\"   API 제한 준수를 위해 70초 대기...\")\n",
    "            await asyncio.sleep(70)\n",
    "    \n",
    "    predictions = results\n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"예측 생성 완료 (총 소요 시간: {generation_time:.1f}초)\")\n",
    "    \n",
    "    # 4. 정답 데이터 준비\n",
    "    references = eval_df['target'].tolist()\n",
    "    \n",
    "    # 5. BERTScore 계산 (대회 공식 계산)\n",
    "    print(\"\\n4. BERTScore 계산 중...\")\n",
    "    bert_scorer = BertScore(model_type=\"distilbert-base-uncased\", batch_size=16)\n",
    "    bert_scores = bert_scorer(refs=references, hyps=predictions)\n",
    "    bert_mean = np.mean(bert_scores)\n",
    "    bert_std = np.std(bert_scores)\n",
    "    \n",
    "    # 6. 공정성 지표 계산 (대회 공식 계산)\n",
    "    print(\"5. 공정성 지표 계산 중...\")\n",
    "    fairness_scorer = FairnessScore(bin_width=10, min_samples_per_group=1)\n",
    "    \n",
    "    # 성별 공정성\n",
    "    gender_fairness = fairness_scorer(\n",
    "        groups=eval_df['gender'].tolist(),\n",
    "        scores=bert_scores,\n",
    "        type='sex'\n",
    "    )\n",
    "    gender_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # 연령 공정성\n",
    "    age_fairness = fairness_scorer(\n",
    "        groups=eval_df['anchor_age'].tolist(),\n",
    "        scores=bert_scores,\n",
    "        type='age'\n",
    "    )\n",
    "    age_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # 7. 대회 정확한 결과 출력\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🎯 Task A 리더보드 정확 평가 결과\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"📊 BERTScore (대회 공식 계산)\")\n",
    "    print(f\"   평균: {bert_mean:.6f}\")\n",
    "    print(f\"   표준편차: {bert_std:.6f}\")\n",
    "    print(f\"   최고: {max(bert_scores):.6f}\")\n",
    "    print(f\"   최저: {min(bert_scores):.6f}\")\n",
    "    print(f\"   중앙값: {np.median(bert_scores):.6f}\")\n",
    "    \n",
    "    print(f\"\\n⚖️ 공정성 지표 (대회 공식 계산)\")\n",
    "    print(f\"   성별 공정성: {gender_fairness:.6f}\")\n",
    "    print(f\"   성별별 성능: {gender_stats['by_group']}\")\n",
    "    print(f\"   성별 격차: {gender_stats['gap']:.6f}\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   연령 공정성: {age_fairness:.6f}\")\n",
    "    print(f\"   연령대별 성능: {age_stats['by_group']}\")\n",
    "    print(f\"   연령 격차: {age_stats['gap']:.6f}\")\n",
    "    \n",
    "    # 8. 정량 평가 점수 계산 (Task A는 16점 만점)\n",
    "    print(f\"\\n🏆 Task A 정량 평가 점수\")\n",
    "    \n",
    "    # BERTScore 점수 (10점 만점 - 16점의 5/8)\n",
    "    bert_score_points = min(10.0, max(0.0, (bert_mean / 0.85) * 10.0))  # 목표 0.85\n",
    "    \n",
    "    # 공정성 점수 (6점 만점 - 16점의 3/8)\n",
    "    fairness_avg = (gender_fairness + age_fairness) / 2.0\n",
    "    fairness_points = min(6.0, max(0.0, (fairness_avg / 0.95) * 6.0))\n",
    "    \n",
    "    # 총점\n",
    "    total_quantitative = bert_score_points + fairness_points\n",
    "    \n",
    "    print(f\"   BERTScore: {bert_score_points:.3f}/10.000 점\")\n",
    "    print(f\"   공정성 지표: {fairness_points:.3f}/6.000 점\")\n",
    "    print(f\"   정량 총점: {total_quantitative:.3f}/16.000 점\")\n",
    "    print(f\"   정량 달성률: {total_quantitative/16.0*100:.1f}%\")\n",
    "    \n",
    "    # 9. 성능 등급 판정\n",
    "    print(f\"\\n🎖️ 성능 등급\")\n",
    "    if total_quantitative >= 14.0:\n",
    "        grade = \"S급 (최우수)\"\n",
    "        recommendation = \"즉시 제출 권장\"\n",
    "    elif total_quantitative >= 12.0:\n",
    "        grade = \"A급 (우수)\"\n",
    "        recommendation = \"제출 권장\"\n",
    "    elif total_quantitative >= 10.0:\n",
    "        grade = \"B급 (양호)\"\n",
    "        recommendation = \"소폭 개선 후 제출\"\n",
    "    else:\n",
    "        grade = \"C급 (보통)\"\n",
    "        recommendation = \"개선 필요\"\n",
    "    \n",
    "    print(f\"   등급: {grade}\")\n",
    "    print(f\"   권장사항: {recommendation}\")\n",
    "    \n",
    "    # 10. 예측 샘플 분석\n",
    "    print(f\"\\n📝 예측 품질 샘플 (상위/하위 각 3개)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    sorted_indices = np.argsort(bert_scores)\n",
    "    \n",
    "    print(\"🏆 최고 성능 샘플:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[-(i+1)]\n",
    "        print(f\"샘플 {idx} (BERTScore: {bert_scores[idx]:.4f})\")\n",
    "        print(f\"예측: {predictions[idx][:200]}...\")\n",
    "        print(f\"정답: {references[idx][:200]}...\")\n",
    "        print()\n",
    "    \n",
    "    print(\"⚠️ 최저 성능 샘플:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[i]\n",
    "        print(f\"샘플 {idx} (BERTScore: {bert_scores[idx]:.4f})\")\n",
    "        print(f\"예측: {predictions[idx][:200]}...\")\n",
    "        print(f\"정답: {references[idx][:200]}...\")\n",
    "        print()\n",
    "    \n",
    "    return {\n",
    "        'bert_score_mean': bert_mean,\n",
    "        'bert_score_std': bert_std,\n",
    "        'bert_scores': bert_scores,\n",
    "        'gender_fairness': gender_fairness,\n",
    "        'age_fairness': age_fairness,\n",
    "        'total_score': total_quantitative,\n",
    "        'grade': grade,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'evaluation_samples': eval_samples,\n",
    "        'processing_time': generation_time\n",
    "    }\n",
    "\n",
    "# 실행\n",
    "API_KEY = \"cfa06ca698c85aa9c9d4b55440aeef0f85ed94f644cd7b931fdd69f2421c6ecb\"\n",
    "TRAIN_CSV_PATH = \"./data/taskA_train.csv\"\n",
    "\n",
    "# Task A 리더보드 정확 평가 실행\n",
    "taskA_results = await exact_taskA_evaluation(\n",
    "    train_csv_path=TRAIN_CSV_PATH,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "print(f\"\\n🎉 Task A 리더보드 평가 완료!\")\n",
    "print(f\"최종 예상 점수: {taskA_results['total_score']:.3f}/16.000 점\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50493b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
