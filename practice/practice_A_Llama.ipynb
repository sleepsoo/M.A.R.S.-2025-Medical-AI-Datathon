{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc941d4",
   "metadata": {},
   "source": [
    "## taskA Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ec5128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/datathon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from typing import Any, List, Dict\n",
    "from typing import Optional, Dict, Any, List, Union\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain.prompts import ChatPromptTemplate  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì²˜ë¦¬ìš©\n",
    "from langevaluate.config import ModelConfig # LLM ì„¤ì •ìš©\n",
    "from langevaluate.llmfactory import LLMFactory  # LLM íŒ©í† ë¦¬ìš©\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import asyncio\n",
    "\n",
    "class DatathonProcessor(ABC):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°í†¤ìš© AI ì²˜ë¦¬ í†µí•© í´ë˜ìŠ¤\n",
    "    ì¿¼ë¦¬, í‰ê°€, ì„ë² ë”©ì„ ì¼ê´„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ìëŠ” ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ íŠ¹ì • ë©”ì„œë“œë§Œ êµ¬í˜„í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # LLM ì„¤ì • ìƒìˆ˜ë“¤\n",
    "    \n",
    "    DEFAULT_MODEL_CONFIG = {\n",
    "        'model_name': 'LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ',\n",
    "        'api_base': 'https://api.snubhai.org/api/v1/llm',\n",
    "        'max_tokens': 2000,\n",
    "        'seed': 777,\n",
    "        'temperature': 0,\n",
    "        'rpm': 10\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key : str,\n",
    "    ):\n",
    "        # ê¸°ë³¸ ì„¤ì • ë³µì‚¬\n",
    "        config = self.DEFAULT_MODEL_CONFIG.copy()\n",
    "        \n",
    "        # model_nameë§Œ í´ë˜ìŠ¤ë³„ ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "        config['model_name'] = self.get_model_name()\n",
    "        \n",
    "        # LLM ì„¤ì • ìƒì„±\n",
    "        custom_config = ModelConfig(\n",
    "            model_name=config['model_name'],\n",
    "            api_base=config['api_base'],\n",
    "            api_key=api_key,\n",
    "            max_tokens=config['max_tokens'],\n",
    "            seed=config['seed'],\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        # LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "        self.llm = LLMFactory.create_llm(\n",
    "            custom_config, \n",
    "            temperature=config['temperature'], \n",
    "            rpm=config['rpm']\n",
    "        )\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥ì†Œ\n",
    "        self.results: List[str] = []\n",
    "        \n",
    "        # metric ì €ì¥ì†Œ\n",
    "        self.metrics: Dict[str, Any] = {}\n",
    "    \n",
    "        \n",
    "    def get_model_name(self) -> str:\n",
    "        \"\"\"\n",
    "        ì‚¬ìš©í•  ëª¨ë¸ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        ìƒì† í´ë˜ìŠ¤ì—ì„œ ì´ ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ íŠ¹ì • ëª¨ë¸ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "        return self.DEFAULT_MODEL_CONFIG['model_name']\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    async def preprocess_data(self, data: Any) -> Dict[str, Any]:\n",
    "        \"\"\"ë°ì´í„° ì „ì²˜ë¦¬ ë©”ì„œë“œ\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_prompt_template(self) -> str:\n",
    "        \"\"\"ì‚¬ìš©ìê°€ êµ¬í˜„í•´ì•¼ í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë©”ì„œë“œ\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def postprocess_result(self, result: Any) -> str:\n",
    "        \"\"\"ë°ì´í„° í›„ì²˜ë¦¬ ë©”ì„œë“œ\"\"\"\n",
    "        pass\n",
    "\n",
    "    async def summarize(\n",
    "        self, \n",
    "        data: pd.DataFrame\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        ë‹¨ì¼ ì…ë ¥ê³¼ ë°°ì¹˜ ì…ë ¥ì„ ëª¨ë‘ ì²˜ë¦¬í•˜ëŠ” í†µí•© ë©”ì„œë“œ\n",
    "        \"\"\"\n",
    "        # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        \n",
    "        preprocess_tasks = [self.preprocess_data(row) for _, row in data.iterrows()]\n",
    "        preprocessed_data = await tqdm_asyncio.gather(*preprocess_tasks)\n",
    "\n",
    "        # ê°ê°ì„ ë³„ë„ì˜ coroutineìœ¼ë¡œ ì‹¤í–‰\n",
    "        tasks = [self.chain.ainvoke(vars) for vars in preprocessed_data]\n",
    "\n",
    "        # tqdm_asyncio.gatherë¡œ ë™ì‹œì— ì‹¤í–‰í•˜ë©° progress bar í‘œì‹œ\n",
    "        responses = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "        postprocess_tasks = [self.postprocess_result(r.content) for r in responses]\n",
    "        results = await tqdm_asyncio.gather(*postprocess_tasks)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbbcc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ† Task A ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹œë®¬ë ˆì´ì…˜\n",
      "================================================================================\n",
      "1. ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "í‰ê°€ ìƒ˜í”Œ: 300ê°œ\n",
      "\n",
      "ğŸ“Š ë°ì´í„° ë¶„í¬:\n",
      "ì„±ë³„: {'M': 155, 'F': 145}\n",
      "ì—°ë ¹: í‰ê·  63.4ì„¸\n",
      "\n",
      "2. TaskA ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (EXAONE ëª¨ë¸)...\n",
      "3. Brief Hospital Course ìƒì„± ì¤‘...\n",
      "   ë°°ì¹˜ 1/38 ì²˜ë¦¬ ì¤‘...\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 2/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 3/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 4/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 5/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 6/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 7/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 8/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 9/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 10/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 11/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 12/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 13/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 14/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 15/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 16/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 17/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 18/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 19/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 20/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 21/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 22/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 23/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 24/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 25/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 26/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 27/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 28/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 29/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 30/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 31/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 32/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 33/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 34/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 35/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 36/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 37/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 38/38 ì²˜ë¦¬ ì¤‘...\n",
      "ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: 5064.9ì´ˆ)\n",
      "\n",
      "4. BERTScore ê³„ì‚° ì¤‘...\n",
      "5. ê³µì •ì„± ì§€í‘œ ê³„ì‚° ì¤‘...\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ Task A ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ê²°ê³¼\n",
      "================================================================================\n",
      "ğŸ“Š BERTScore (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
      "   í‰ê· : 0.771005\n",
      "   í‘œì¤€í¸ì°¨: 0.020697\n",
      "   ìµœê³ : 0.813723\n",
      "   ìµœì €: 0.684786\n",
      "   ì¤‘ì•™ê°’: 0.773139\n",
      "\n",
      "âš–ï¸ ê³µì •ì„± ì§€í‘œ (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
      "   ì„±ë³„ ê³µì •ì„±: 0.994164\n",
      "   ì„±ë³„ë³„ ì„±ëŠ¥: {'F': 0.7733365387752138, 'M': 0.7688233417849387}\n",
      "   ì„±ë³„ ê²©ì°¨: 0.004513\n",
      "   \n",
      "   ì—°ë ¹ ê³µì •ì„±: 0.977805\n",
      "   ì—°ë ¹ëŒ€ë³„ ì„±ëŠ¥: {'10-20': 0.766829252243042, '20-30': 0.7700861061320585, '30-40': 0.778713047504425, '40-50': 0.7758198868144642, '50-60': 0.7715244720379512, '60-70': 0.7722391301477459, '70-80': 0.7731823652398353, '80-90': 0.7614295316296954, '90-100': 0.7700086385011673}\n",
      "   ì—°ë ¹ ê²©ì°¨: 0.017284\n",
      "\n",
      "ğŸ† Task A ì •ëŸ‰ í‰ê°€ ì ìˆ˜\n",
      "   BERTScore: 9.071/10.000 ì \n",
      "   ê³µì •ì„± ì§€í‘œ: 6.000/6.000 ì \n",
      "   ì •ëŸ‰ ì´ì : 15.071/16.000 ì \n",
      "   ì •ëŸ‰ ë‹¬ì„±ë¥ : 94.2%\n",
      "\n",
      "ğŸ–ï¸ ì„±ëŠ¥ ë“±ê¸‰\n",
      "   ë“±ê¸‰: Sê¸‰ (ìµœìš°ìˆ˜)\n",
      "   ê¶Œì¥ì‚¬í•­: ì¦‰ì‹œ ì œì¶œ ê¶Œì¥\n",
      "\n",
      "ğŸ“ ì˜ˆì¸¡ í’ˆì§ˆ ìƒ˜í”Œ (ìƒìœ„/í•˜ìœ„ ê° 3ê°œ)\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ† ìµœê³  ì„±ëŠ¥ ìƒ˜í”Œ:\n",
      "ìƒ˜í”Œ 169 (BERTScore: 0.8137)\n",
      "ì˜ˆì¸¡: Ms. ___, a 35-year-old female, was admitted to the Neurosurgery service with a chief complaint of unsteady gait and a history of a recent syncopal event. She underwent a routine outpatient head MRI fo...\n",
      "ì •ë‹µ: Mrs. ___ was admitted to the ___ Neurosurgery service \n",
      "for management of her left subdural hematoma.  She underwent \n",
      "work-up for her questionable syncopal epside.  An echocardiogram \n",
      "showed normal biv...\n",
      "\n",
      "ìƒ˜í”Œ 72 (BERTScore: 0.8124)\n",
      "ì˜ˆì¸¡: Ms. ___ was admitted to the Neurosurgery service with a chief complaint of a right subdural hematoma with midline shift. She was a  [REDACTED] year-old female with a significant past medical history o...\n",
      "ì •ë‹µ: Mrs. ___ was admitted to the Neurosurgery service on ___ \n",
      "for further management and observation after suffering a fall \n",
      "resulting a left acute on chronic subdural hematoma.  As she was \n",
      "intubated for...\n",
      "\n",
      "ìƒ˜í”Œ 187 (BERTScore: 0.8110)\n",
      "ì˜ˆì¸¡: Mr. [REDACTED], a 65-year-old male with a history of Type A aortic dissection and aortic valve replacement (AVR), was admitted to the medicine service for evaluation of headaches and fevers. \n",
      "\n",
      "**Admis...\n",
      "ì •ë‹µ: Mr. ___ is a ___ YO male with a history of AVR ___ \n",
      "___ ___ replacement after Type A aortic dissection, who \n",
      "presented as an OSH transfer due to concern for meningitis. \n",
      "Work-up revealed anaplasmosis ...\n",
      "\n",
      "âš ï¸ ìµœì € ì„±ëŠ¥ ìƒ˜í”Œ:\n",
      "ìƒ˜í”Œ 125 (BERTScore: 0.6848)\n",
      "ì˜ˆì¸¡: Mr. [REDACTED] was admitted to the medicine service with a chief complaint of nausea and vomiting. His past medical history is notable for hypertension, benign prostatic hyperplasia (BPH), and a histo...\n",
      "ì •ë‹µ: Mr. ___ is a lovely ___ year old man with hypertension & history \n",
      "of carotid stenosis who presented with nausea & vomiting x3 \n",
      "days. \n",
      "\n",
      "================...\n",
      "\n",
      "ìƒ˜í”Œ 127 (BERTScore: 0.7049)\n",
      "ì˜ˆì¸¡: Mr. [REDACTED] was admitted to the medicine service for evaluation and management of symptomatic bradycardia. He presented with a chief complaint of intermittent episodes of dizziness and lightheadedn...\n",
      "ì •ë‹µ: =======================\n",
      "SUMMARY STATEMENT\n",
      "=======================\n",
      "\n",
      "Mr ___ is a ___ y/o M with PMH significant for rheumatic heart\n",
      "disease who presented with several weeks of lightheadedness and \n",
      "brady...\n",
      "\n",
      "ìƒ˜í”Œ 39 (BERTScore: 0.7075)\n",
      "ì˜ˆì¸¡: Ms. ___ was admitted to the medicine service for management of a percutaneously placed cholecystostomy tube and evaluation of bilateral pleural effusions. She presented with a history of recurrent cho...\n",
      "ì •ë‹µ: Discharge Worksheet - Key Information for Outpatient \n",
      "___, MD on ___ @ 1608 ...\n",
      "\n",
      "\n",
      "ğŸ‰ Task A ë¦¬ë”ë³´ë“œ í‰ê°€ ì™„ë£Œ!\n",
      "ìµœì¢… ì˜ˆìƒ ì ìˆ˜: 15.071/16.000 ì \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import asyncio\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "from bert_score import BERTScorer\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langevaluate.config import ModelConfig\n",
    "from langevaluate.llmfactory import LLMFactory\n",
    "import re\n",
    "\n",
    "# ëŒ€íšŒ ì œê³µ BertScore í´ë˜ìŠ¤ (100% ë™ì¼)\n",
    "class BertScore:\n",
    "    def __init__(self, model_type=\"distilbert-base-uncased\", batch_size=16):\n",
    "        with torch.no_grad():\n",
    "            self.bert_scorer = BERTScorer(\n",
    "                model_type=model_type,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "\n",
    "    def __call__(self, refs, hyps):\n",
    "        p, r, f = self.bert_scorer.score(\n",
    "            cands=hyps,\n",
    "            refs=refs,\n",
    "            verbose=False,\n",
    "            batch_size=8,\n",
    "        )\n",
    "        return f.tolist()\n",
    "\n",
    "# ëŒ€íšŒ ì œê³µ FairnessScore í´ë˜ìŠ¤ (100% ë™ì¼)\n",
    "class FairnessScore:\n",
    "    def __init__(self, bin_width: int = 10, min_samples_per_group: int = 1):\n",
    "        self.bin_width = int(bin_width)\n",
    "        self.min_samples_per_group = int(min_samples_per_group)\n",
    "        self.last_stats = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_1d(a) -> np.ndarray:\n",
    "        a = np.asarray(a)\n",
    "        if a.ndim == 2 and a.shape[1] == 1:\n",
    "            a = a[:, 0]\n",
    "        if a.ndim != 1:\n",
    "            raise ValueError(\"Input must be 1D or (N,1) shaped.\")\n",
    "        return a\n",
    "\n",
    "    def _bin_ages(self, ages) -> np.ndarray:\n",
    "        a = self._ensure_1d(ages).astype(float)\n",
    "        if np.any(np.isnan(a)):\n",
    "            raise ValueError(\"ages contain NaN.\")\n",
    "        if self.bin_width <= 0:\n",
    "            raise ValueError(\"bin_width must be positive.\")\n",
    "        starts = (np.floor(a / self.bin_width) * self.bin_width).astype(int)\n",
    "        ends = starts + self.bin_width\n",
    "        labels = np.array([f\"{s:d}-{e:d}\" for s, e in zip(starts, ends)], dtype=object)\n",
    "        return labels\n",
    "\n",
    "    def _groups_from_type(self, groups, type: str) -> np.ndarray:\n",
    "        t = (type or \"sex\").lower()\n",
    "        if t not in (\"sex\", \"age\"):\n",
    "            raise ValueError(\"type must be 'sex' or 'age'.\")\n",
    "        if t == \"sex\":\n",
    "            g = self._ensure_1d(groups)\n",
    "            return g\n",
    "        else:\n",
    "            return self._bin_ages(groups)\n",
    "\n",
    "    def __call__(self, groups, scores, type: str = \"sex\", sample_weight=None) -> float:\n",
    "        g = self._groups_from_type(groups, type=type)\n",
    "        s = self._ensure_1d(scores).astype(float)\n",
    "        if s.shape[0] != g.shape[0]:\n",
    "            raise ValueError(\"groups and scores must have the same length.\")\n",
    "\n",
    "        if sample_weight is None:\n",
    "            w = np.ones_like(s, dtype=float)\n",
    "        else:\n",
    "            w = self._ensure_1d(sample_weight).astype(float)\n",
    "            if w.shape[0] != s.shape[0]:\n",
    "                raise ValueError(\"sample_weight length must match scores.\")\n",
    "\n",
    "        s = np.clip(s, 0.0, 1.0)\n",
    "\n",
    "        uniq = np.unique(g)\n",
    "        means = []\n",
    "        by_group = {}\n",
    "        for grp in uniq:\n",
    "            mask = (g == grp)\n",
    "            if np.sum(mask) < self.min_samples_per_group:\n",
    "                continue\n",
    "            denom = np.sum(w[mask])\n",
    "            if denom <= 0:\n",
    "                continue\n",
    "            m = float(np.average(s[mask], weights=w[mask]))\n",
    "            means.append(m)\n",
    "            by_group[str(grp)] = m\n",
    "\n",
    "        if len(means) <= 1:\n",
    "            self.last_stats = {\"by_group\": by_group, \"gap\": 0.0, \"min\": None, \"max\": None}\n",
    "            return 1.0\n",
    "\n",
    "        max_m = float(np.max(means))\n",
    "        min_m = float(np.min(means))\n",
    "        fairness = 1.0 if max_m == 0.0 else float(min_m / max_m)\n",
    "        fairness = float(np.clip(fairness, 0.0, 1.0))\n",
    "\n",
    "        self.last_stats = {\"by_group\": by_group, \"gap\": max_m - min_m, \"min\": min_m, \"max\": max_m}\n",
    "        return fairness\n",
    "\n",
    "# TaskA Processor (ì•ì„œ ì‘ì„±í•œ ìµœì í™” ë²„ì „)\n",
    "class TaskAProcessor:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        \n",
    "        config = ModelConfig(\n",
    "            # model_name=\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\",\n",
    "            model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "            api_base=\"https://api.snubhai.org/api/v1/llm\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=1500,\n",
    "            seed=777,\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        self.llm = LLMFactory.create_llm(config, temperature=0, rpm=10)\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"You are a senior attending physician with 15+ years of experience writing comprehensive Brief Hospital Course summaries. Create a professional, chronologically structured summary that captures the essential medical narrative.\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Write 250-400 words (optimal length based on successful cases)\n",
    "- Maintain chronological flow: Admission â†’ Course â†’ Outcome\n",
    "- Use precise medical terminology consistently\n",
    "- Include key diagnostic findings, treatments, and patient responses\n",
    "- Maintain professional tone regardless of patient demographics\n",
    "- Focus on clinically significant events and interventions\n",
    "\n",
    "STRUCTURE METHODOLOGY:\n",
    "1. Opening: Patient presentation and admission reason\n",
    "2. Initial Assessment: Key findings, diagnostics, initial diagnosis\n",
    "3. Hospital Course: Chronological treatment progression, complications\n",
    "4. Clinical Response: Patient improvement/deterioration, interventions\n",
    "5. Discharge Planning: Final status, disposition, follow-up needs\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "MEDICAL RECORD: [Complex gynecologic oncology case...]\n",
    "BRIEF HOSPITAL COURSE: Ms. ___ was admitted to the gynecologic oncology service after undergoing diagnostic laparoscopy converted to exploratory laparotomy, total abdominal hysterectomy, bilateral salpingo-oophrectomy, omentectomy, pelvic and para-aortic lymph node dissection, and tumor debulking for Stage IIIC ovarian carcinoma. Her postoperative course was complicated by prolonged ileus requiring nasogastric decompression and total parenteral nutrition. She developed a wound infection on postoperative day 5 treated with antibiotics and wound care. Patient was discharged home on postoperative day 8 in stable condition with visiting nurse services arranged.\n",
    "\n",
    "MEDICAL RECORD: [Cardiac case with preoperative evaluation...]\n",
    "BRIEF HOSPITAL COURSE: He was admitted to the cardiology service and remained chest pain free. He underwent routine preoperative testing and evaluation. He developed early signs of gout flare in the right and left hallux which was treated with colchicine and responded well. His cardiac catheterization revealed severe three-vessel coronary artery disease requiring surgical revascularization. He was medically optimized and discharged home after 3 days in stable condition with cardiothoracic surgery follow-up scheduled.\n",
    "\n",
    "Now create a Brief Hospital Course for:\n",
    "\n",
    "MEDICAL RECORD: {user_input}\n",
    "\n",
    "BRIEF HOSPITAL COURSE:\"\"\"\n",
    "\n",
    "    async def preprocess_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        medical_record = data['medical record']\n",
    "        \n",
    "        if pd.isna(medical_record) or not isinstance(medical_record, str):\n",
    "            return {'user_input': ''}\n",
    "        \n",
    "        processed_sections = []\n",
    "        \n",
    "        # Chief Complaint & Service\n",
    "        if 'Chief Complaint:' in medical_record:\n",
    "            cc_match = re.search(r'Chief Complaint:\\s*([^\\n]+)', medical_record)\n",
    "            if cc_match:\n",
    "                processed_sections.append(f\"Chief Complaint: {cc_match.group(1).strip()}\")\n",
    "        \n",
    "        if 'Service:' in medical_record:\n",
    "            service_match = re.search(r'Service:\\s*([^\\n]+)', medical_record)\n",
    "            if service_match:\n",
    "                processed_sections.append(f\"Service: {service_match.group(1).strip()}\")\n",
    "        \n",
    "        # History of Present Illness\n",
    "        if 'History of Present Illness:' in medical_record:\n",
    "            hpi_match = re.search(r'History of Present Illness:\\s*(.*?)(?=\\n\\n|\\nPast Medical|Physical Exam|$)', \n",
    "                                medical_record, re.DOTALL)\n",
    "            if hpi_match:\n",
    "                hpi = hpi_match.group(1).strip()[:800]\n",
    "                processed_sections.append(f\"History: {hpi}\")\n",
    "        \n",
    "        # Major Procedures\n",
    "        if 'Major Surgical or Invasive Procedure:' in medical_record:\n",
    "            proc_match = re.search(r'Major Surgical or Invasive Procedure:\\s*(.*?)(?=\\n\\n|History of Present|$)', \n",
    "                                 medical_record, re.DOTALL)\n",
    "            if proc_match:\n",
    "                proc = proc_match.group(1).strip()\n",
    "                if proc.lower() not in ['none', 'none.']:\n",
    "                    processed_sections.append(f\"Major Procedures: {proc}\")\n",
    "        \n",
    "        # Past Medical History\n",
    "        if 'Past Medical History:' in medical_record:\n",
    "            pmh_match = re.search(r'Past Medical History:\\s*(.*?)(?=\\n\\n|PAST SURGICAL|Social History|$)',\n",
    "                                medical_record, re.DOTALL)\n",
    "            if pmh_match:\n",
    "                pmh = pmh_match.group(1).strip()[:400]\n",
    "                processed_sections.append(f\"Past Medical History: {pmh}\")\n",
    "        \n",
    "        # Imaging IMPRESSION\n",
    "        impressions = re.findall(r'IMPRESSION:\\s*(.*?)(?=\\n\\n|\\n[A-Z_]|\\Z)', medical_record, re.DOTALL)\n",
    "        if impressions:\n",
    "            for i, imp in enumerate(impressions[:2]):\n",
    "                processed_sections.append(f\"Imaging {i+1}: {imp.strip()[:200]}\")\n",
    "        \n",
    "        processed_text = '\\n\\n'.join(processed_sections)\n",
    "        processed_text = re.sub(r'___+', '[REDACTED]', processed_text)\n",
    "        processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
    "        processed_text = processed_text[:3000]\n",
    "        \n",
    "        return {'user_input': processed_text.strip()}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        result = result.strip()\n",
    "        \n",
    "        prefixes = ['BRIEF HOSPITAL COURSE:', 'Brief Hospital Course:', 'brief hospital course:']\n",
    "        for prefix in prefixes:\n",
    "            if result.startswith(prefix):\n",
    "                result = result[len(prefix):].strip()\n",
    "        \n",
    "        if result and not result.endswith('.'):\n",
    "            result += '.'\n",
    "        \n",
    "        # ë‹¨ì–´ ìˆ˜ ìµœì í™”\n",
    "        words = result.split()\n",
    "        if len(words) > 450:\n",
    "            sentences = [s.strip() for s in result.split('.') if s.strip()]\n",
    "            important_keywords = ['admitted', 'diagnosis', 'treated', 'underwent', 'developed', \n",
    "                                'improved', 'discharged', 'course', 'complication']\n",
    "            \n",
    "            important_sentences = []\n",
    "            for sentence in sentences:\n",
    "                if any(keyword in sentence.lower() for keyword in important_keywords) or len(important_sentences) < 3:\n",
    "                    important_sentences.append(sentence.strip())\n",
    "                if len(' '.join(important_sentences).split()) >= 400:\n",
    "                    break\n",
    "            \n",
    "            if important_sentences:\n",
    "                result = '. '.join(important_sentences)\n",
    "                if not result.endswith('.'):\n",
    "                    result += '.'\n",
    "        \n",
    "        # ì˜ë£Œ ìš©ì–´ í‘œì¤€í™”\n",
    "        medical_corrections = {\n",
    "            'pt ': 'patient ',\n",
    "            'w/ ': 'with ',\n",
    "            'w/o ': 'without ',\n",
    "            'h/o ': 'history of '\n",
    "        }\n",
    "        \n",
    "        for wrong, correct in medical_corrections.items():\n",
    "            result = result.replace(wrong, correct)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ë¦¬ë”ë³´ë“œ 100% ë™ì¼ í‰ê°€ í•¨ìˆ˜\n",
    "async def exact_taskA_evaluation(train_csv_path: str, api_key: str):\n",
    "    \"\"\"ëŒ€íšŒ ë¦¬ë”ë³´ë“œì™€ ì •í™•íˆ ë™ì¼í•œ Task A í‰ê°€\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ† Task A ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹œë®¬ë ˆì´ì…˜\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    print(\"1. ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "    df = pd.read_csv(train_csv_path)\n",
    "    df = df.dropna(subset=['medical record', 'target'])\n",
    "    \n",
    "    eval_samples = min(300, len(df))\n",
    "    eval_df = df.iloc[:eval_samples].copy()\n",
    "    print(f\"í‰ê°€ ìƒ˜í”Œ: {eval_samples}ê°œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í¬:\")\n",
    "    print(f\"ì„±ë³„: {eval_df['gender'].value_counts().to_dict()}\")\n",
    "    print(f\"ì—°ë ¹: í‰ê·  {eval_df['anchor_age'].mean():.1f}ì„¸\")\n",
    "    \n",
    "    # 2. TaskA ì²˜ë¦¬ê¸° ì´ˆê¸°í™”\n",
    "    print(\"\\n2. TaskA ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (EXAONE ëª¨ë¸)...\")\n",
    "    processor = TaskAProcessor(api_key)\n",
    "    \n",
    "    # 3. ì˜ˆì¸¡ ìƒì„±\n",
    "    print(\"3. Brief Hospital Course ìƒì„± ì¤‘...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    data_batch = [{'medical record': row['medical record']} for _, row in eval_df.iterrows()]\n",
    "    \n",
    "    results = []\n",
    "    batch_size = 8\n",
    "    \n",
    "    for i in range(0, len(data_batch), batch_size):\n",
    "        batch = data_batch[i:i+batch_size]\n",
    "        print(f\"   ë°°ì¹˜ {i//batch_size + 1}/{(len(data_batch)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ì „ì²˜ë¦¬\n",
    "        preprocessed = [await processor.preprocess_data(row) for row in batch]\n",
    "        \n",
    "        # API í˜¸ì¶œ\n",
    "        tasks = [processor.chain.ainvoke(prep) for prep in preprocessed]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # í›„ì²˜ë¦¬\n",
    "        batch_results = [await processor.postprocess_result(r.content) for r in responses]\n",
    "        results.extend(batch_results)\n",
    "        \n",
    "        # API ì œí•œ ì¤€ìˆ˜\n",
    "        if i + batch_size < len(data_batch):\n",
    "            print(f\"   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\")\n",
    "            await asyncio.sleep(70)\n",
    "    \n",
    "    predictions = results\n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {generation_time:.1f}ì´ˆ)\")\n",
    "    \n",
    "    # 4. ì •ë‹µ ë°ì´í„° ì¤€ë¹„\n",
    "    references = eval_df['target'].tolist()\n",
    "    \n",
    "    # 5. BERTScore ê³„ì‚° (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
    "    print(\"\\n4. BERTScore ê³„ì‚° ì¤‘...\")\n",
    "    bert_scorer = BertScore(model_type=\"distilbert-base-uncased\", batch_size=16)\n",
    "    bert_scores = bert_scorer(refs=references, hyps=predictions)\n",
    "    bert_mean = np.mean(bert_scores)\n",
    "    bert_std = np.std(bert_scores)\n",
    "    \n",
    "    # 6. ê³µì •ì„± ì§€í‘œ ê³„ì‚° (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
    "    print(\"5. ê³µì •ì„± ì§€í‘œ ê³„ì‚° ì¤‘...\")\n",
    "    fairness_scorer = FairnessScore(bin_width=10, min_samples_per_group=1)\n",
    "    \n",
    "    # ì„±ë³„ ê³µì •ì„±\n",
    "    gender_fairness = fairness_scorer(\n",
    "        groups=eval_df['gender'].tolist(),\n",
    "        scores=bert_scores,\n",
    "        type='sex'\n",
    "    )\n",
    "    gender_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # ì—°ë ¹ ê³µì •ì„±\n",
    "    age_fairness = fairness_scorer(\n",
    "        groups=eval_df['anchor_age'].tolist(),\n",
    "        scores=bert_scores,\n",
    "        type='age'\n",
    "    )\n",
    "    age_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # 7. ëŒ€íšŒ ì •í™•í•œ ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ¯ Task A ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"ğŸ“Š BERTScore (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\")\n",
    "    print(f\"   í‰ê· : {bert_mean:.6f}\")\n",
    "    print(f\"   í‘œì¤€í¸ì°¨: {bert_std:.6f}\")\n",
    "    print(f\"   ìµœê³ : {max(bert_scores):.6f}\")\n",
    "    print(f\"   ìµœì €: {min(bert_scores):.6f}\")\n",
    "    print(f\"   ì¤‘ì•™ê°’: {np.median(bert_scores):.6f}\")\n",
    "    \n",
    "    print(f\"\\nâš–ï¸ ê³µì •ì„± ì§€í‘œ (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\")\n",
    "    print(f\"   ì„±ë³„ ê³µì •ì„±: {gender_fairness:.6f}\")\n",
    "    print(f\"   ì„±ë³„ë³„ ì„±ëŠ¥: {gender_stats['by_group']}\")\n",
    "    print(f\"   ì„±ë³„ ê²©ì°¨: {gender_stats['gap']:.6f}\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   ì—°ë ¹ ê³µì •ì„±: {age_fairness:.6f}\")\n",
    "    print(f\"   ì—°ë ¹ëŒ€ë³„ ì„±ëŠ¥: {age_stats['by_group']}\")\n",
    "    print(f\"   ì—°ë ¹ ê²©ì°¨: {age_stats['gap']:.6f}\")\n",
    "    \n",
    "    # 8. ì •ëŸ‰ í‰ê°€ ì ìˆ˜ ê³„ì‚° (Task AëŠ” 16ì  ë§Œì )\n",
    "    print(f\"\\nğŸ† Task A ì •ëŸ‰ í‰ê°€ ì ìˆ˜\")\n",
    "    \n",
    "    # BERTScore ì ìˆ˜ (10ì  ë§Œì  - 16ì ì˜ 5/8)\n",
    "    bert_score_points = min(10.0, max(0.0, (bert_mean / 0.85) * 10.0))  # ëª©í‘œ 0.85\n",
    "    \n",
    "    # ê³µì •ì„± ì ìˆ˜ (6ì  ë§Œì  - 16ì ì˜ 3/8)\n",
    "    fairness_avg = (gender_fairness + age_fairness) / 2.0\n",
    "    fairness_points = min(6.0, max(0.0, (fairness_avg / 0.95) * 6.0))\n",
    "    \n",
    "    # ì´ì \n",
    "    total_quantitative = bert_score_points + fairness_points\n",
    "    \n",
    "    print(f\"   BERTScore: {bert_score_points:.3f}/10.000 ì \")\n",
    "    print(f\"   ê³µì •ì„± ì§€í‘œ: {fairness_points:.3f}/6.000 ì \")\n",
    "    print(f\"   ì •ëŸ‰ ì´ì : {total_quantitative:.3f}/16.000 ì \")\n",
    "    print(f\"   ì •ëŸ‰ ë‹¬ì„±ë¥ : {total_quantitative/16.0*100:.1f}%\")\n",
    "    \n",
    "    # 9. ì„±ëŠ¥ ë“±ê¸‰ íŒì •\n",
    "    print(f\"\\nğŸ–ï¸ ì„±ëŠ¥ ë“±ê¸‰\")\n",
    "    if total_quantitative >= 14.0:\n",
    "        grade = \"Sê¸‰ (ìµœìš°ìˆ˜)\"\n",
    "        recommendation = \"ì¦‰ì‹œ ì œì¶œ ê¶Œì¥\"\n",
    "    elif total_quantitative >= 12.0:\n",
    "        grade = \"Aê¸‰ (ìš°ìˆ˜)\"\n",
    "        recommendation = \"ì œì¶œ ê¶Œì¥\"\n",
    "    elif total_quantitative >= 10.0:\n",
    "        grade = \"Bê¸‰ (ì–‘í˜¸)\"\n",
    "        recommendation = \"ì†Œí­ ê°œì„  í›„ ì œì¶œ\"\n",
    "    else:\n",
    "        grade = \"Cê¸‰ (ë³´í†µ)\"\n",
    "        recommendation = \"ê°œì„  í•„ìš”\"\n",
    "    \n",
    "    print(f\"   ë“±ê¸‰: {grade}\")\n",
    "    print(f\"   ê¶Œì¥ì‚¬í•­: {recommendation}\")\n",
    "    \n",
    "    # 10. ì˜ˆì¸¡ ìƒ˜í”Œ ë¶„ì„\n",
    "    print(f\"\\nğŸ“ ì˜ˆì¸¡ í’ˆì§ˆ ìƒ˜í”Œ (ìƒìœ„/í•˜ìœ„ ê° 3ê°œ)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    sorted_indices = np.argsort(bert_scores)\n",
    "    \n",
    "    print(\"ğŸ† ìµœê³  ì„±ëŠ¥ ìƒ˜í”Œ:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[-(i+1)]\n",
    "        print(f\"ìƒ˜í”Œ {idx} (BERTScore: {bert_scores[idx]:.4f})\")\n",
    "        print(f\"ì˜ˆì¸¡: {predictions[idx][:200]}...\")\n",
    "        print(f\"ì •ë‹µ: {references[idx][:200]}...\")\n",
    "        print()\n",
    "    \n",
    "    print(\"âš ï¸ ìµœì € ì„±ëŠ¥ ìƒ˜í”Œ:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[i]\n",
    "        print(f\"ìƒ˜í”Œ {idx} (BERTScore: {bert_scores[idx]:.4f})\")\n",
    "        print(f\"ì˜ˆì¸¡: {predictions[idx][:200]}...\")\n",
    "        print(f\"ì •ë‹µ: {references[idx][:200]}...\")\n",
    "        print()\n",
    "    \n",
    "    return {\n",
    "        'bert_score_mean': bert_mean,\n",
    "        'bert_score_std': bert_std,\n",
    "        'bert_scores': bert_scores,\n",
    "        'gender_fairness': gender_fairness,\n",
    "        'age_fairness': age_fairness,\n",
    "        'total_score': total_quantitative,\n",
    "        'grade': grade,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'evaluation_samples': eval_samples,\n",
    "        'processing_time': generation_time\n",
    "    }\n",
    "\n",
    "# ì‹¤í–‰\n",
    "API_KEY = \"cfa06ca698c85aa9c9d4b55440aeef0f85ed94f644cd7b931fdd69f2421c6ecb\"\n",
    "TRAIN_CSV_PATH = \"./data/taskA_train.csv\"\n",
    "\n",
    "# Task A ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹¤í–‰\n",
    "taskA_results = await exact_taskA_evaluation(\n",
    "    train_csv_path=TRAIN_CSV_PATH,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ‰ Task A ë¦¬ë”ë³´ë“œ í‰ê°€ ì™„ë£Œ!\")\n",
    "print(f\"ìµœì¢… ì˜ˆìƒ ì ìˆ˜: {taskA_results['total_score']:.3f}/16.000 ì \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50493b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
