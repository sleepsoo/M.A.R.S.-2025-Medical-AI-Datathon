{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f2d65f",
   "metadata": {},
   "source": [
    "## Datathon í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d89df59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/datathon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from typing import Any, List, Dict\n",
    "from typing import Optional, Dict, Any, List, Union\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain.prompts import ChatPromptTemplate  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì²˜ë¦¬ìš©\n",
    "from langevaluate.config import ModelConfig # LLM ì„¤ì •ìš©\n",
    "from langevaluate.llmfactory import LLMFactory  # LLM íŒ©í† ë¦¬ìš©\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import asyncio\n",
    "\n",
    "class DatathonProcessor(ABC):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°í†¤ìš© AI ì²˜ë¦¬ í†µí•© í´ë˜ìŠ¤\n",
    "    ì¿¼ë¦¬, í‰ê°€, ì„ë² ë”©ì„ ì¼ê´„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ìëŠ” ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ íŠ¹ì • ë©”ì„œë“œë§Œ êµ¬í˜„í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # LLM ì„¤ì • ìƒìˆ˜ë“¤\n",
    "    \n",
    "    DEFAULT_MODEL_CONFIG = {\n",
    "        'model_name': 'LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ',\n",
    "        'api_base': 'https://api.snubhai.org/api/v1/llm',\n",
    "        'max_tokens': 2000,\n",
    "        'seed': 777,\n",
    "        'temperature': 0,\n",
    "        'rpm': 10\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key : str,\n",
    "    ):\n",
    "        # ê¸°ë³¸ ì„¤ì • ë³µì‚¬\n",
    "        config = self.DEFAULT_MODEL_CONFIG.copy()\n",
    "        \n",
    "        # model_nameë§Œ í´ë˜ìŠ¤ë³„ ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "        config['model_name'] = self.get_model_name()\n",
    "        \n",
    "        # LLM ì„¤ì • ìƒì„±\n",
    "        custom_config = ModelConfig(\n",
    "            model_name=config['model_name'],\n",
    "            api_base=config['api_base'],\n",
    "            api_key=api_key,\n",
    "            max_tokens=config['max_tokens'],\n",
    "            seed=config['seed'],\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        # LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "        self.llm = LLMFactory.create_llm(\n",
    "            custom_config, \n",
    "            temperature=config['temperature'], \n",
    "            rpm=config['rpm']\n",
    "        )\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥ì†Œ\n",
    "        self.results: List[str] = []\n",
    "        \n",
    "        # metric ì €ì¥ì†Œ\n",
    "        self.metrics: Dict[str, Any] = {}\n",
    "    \n",
    "        \n",
    "    def get_model_name(self) -> str:\n",
    "        \"\"\"\n",
    "        ì‚¬ìš©í•  ëª¨ë¸ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        ìƒì† í´ë˜ìŠ¤ì—ì„œ ì´ ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ íŠ¹ì • ëª¨ë¸ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "        return self.DEFAULT_MODEL_CONFIG['model_name']\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    async def preprocess_data(self, data: Any) -> Dict[str, Any]:\n",
    "        \"\"\"ë°ì´í„° ì „ì²˜ë¦¬ ë©”ì„œë“œ\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_prompt_template(self) -> str:\n",
    "        \"\"\"ì‚¬ìš©ìê°€ êµ¬í˜„í•´ì•¼ í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë©”ì„œë“œ\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def postprocess_result(self, result: Any) -> str:\n",
    "        \"\"\"ë°ì´í„° í›„ì²˜ë¦¬ ë©”ì„œë“œ\"\"\"\n",
    "        pass\n",
    "\n",
    "    async def summarize(\n",
    "        self, \n",
    "        data: pd.DataFrame\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        ë‹¨ì¼ ì…ë ¥ê³¼ ë°°ì¹˜ ì…ë ¥ì„ ëª¨ë‘ ì²˜ë¦¬í•˜ëŠ” í†µí•© ë©”ì„œë“œ\n",
    "        \"\"\"\n",
    "        # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        \n",
    "        preprocess_tasks = [self.preprocess_data(row) for _, row in data.iterrows()]\n",
    "        preprocessed_data = await tqdm_asyncio.gather(*preprocess_tasks)\n",
    "\n",
    "        # ê°ê°ì„ ë³„ë„ì˜ coroutineìœ¼ë¡œ ì‹¤í–‰\n",
    "        tasks = [self.chain.ainvoke(vars) for vars in preprocessed_data]\n",
    "\n",
    "        # tqdm_asyncio.gatherë¡œ ë™ì‹œì— ì‹¤í–‰í•˜ë©° progress bar í‘œì‹œ\n",
    "        responses = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "        postprocess_tasks = [self.postprocess_result(r.content) for r in responses]\n",
    "        results = await tqdm_asyncio.gather(*postprocess_tasks)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6cec2",
   "metadata": {},
   "source": [
    "## Few-shotìš© ë°ì´í„° ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9035c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ë°ì´í„°: 1000ê°œ\n",
      "ìœ íš¨ ë°ì´í„°: 1000ê°œ\n",
      "\n",
      "ğŸ“Š ê¸°ë³¸ í†µê³„:\n",
      "ICD ì½”ë“œ ê°œìˆ˜: í‰ê·  1.6, ë²”ìœ„ 1-6\n",
      "í…ìŠ¤íŠ¸ ê¸¸ì´: í‰ê·  6192ì, ë²”ìœ„ 984-32945\n",
      "ë‹¨ì–´ ìˆ˜: í‰ê·  890ê°œ, ë²”ìœ„ 126-4437\n",
      "=== ê³ í’ˆì§ˆ ì˜ˆì‹œ 1 (ì ìˆ˜: 15) ===\n",
      "ICD ê°œìˆ˜: 2, ì¹´í…Œê³ ë¦¬: 2\n",
      "ICD ì½”ë“œ: ['S066X1A', 'W1830XA']\n",
      "í…ìŠ¤íŠ¸ ê¸¸ì´: 1365ì\n",
      "ë³‘ì› ê¸°ë¡: Name:  ___               Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: NEUROSURGERY\n",
      " \n",
      "Allergies: \n",
      "No Known Allergies / ...\n",
      "--------------------------------------------------------------------------------\n",
      "=== ê³ í’ˆì§ˆ ì˜ˆì‹œ 2 (ì ìˆ˜: 15) ===\n",
      "ICD ê°œìˆ˜: 2, ì¹´í…Œê³ ë¦¬: 2\n",
      "ICD ì½”ë“œ: ['M5489', 'R339']\n",
      "í…ìŠ¤íŠ¸ ê¸¸ì´: 5299ì\n",
      "ë³‘ì› ê¸°ë¡: Name:  ___                 Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "lisinopril\n",
      " \n",
      "Attending:...\n",
      "--------------------------------------------------------------------------------\n",
      "=== ê³ í’ˆì§ˆ ì˜ˆì‹œ 3 (ì ìˆ˜: 15) ===\n",
      "ICD ê°œìˆ˜: 2, ì¹´í…Œê³ ë¦¬: 2\n",
      "ICD ì½”ë“œ: ['I609', 'R001']\n",
      "í…ìŠ¤íŠ¸ ê¸¸ì´: 4136ì\n",
      "ë³‘ì› ê¸°ë¡: Name:  ___                Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   M\n",
      " \n",
      "Service: NEUROSURGERY\n",
      " \n",
      "Allergies: \n",
      "nicotene patch\n",
      " \n",
      "Att...\n",
      "--------------------------------------------------------------------------------\n",
      "=== ê³ í’ˆì§ˆ ì˜ˆì‹œ 4 (ì ìˆ˜: 15) ===\n",
      "ICD ê°œìˆ˜: 3, ì¹´í…Œê³ ë¦¬: 3\n",
      "ICD ì½”ë“œ: ['F308', 'T380X5A', 'Y9289']\n",
      "í…ìŠ¤íŠ¸ ê¸¸ì´: 5414ì\n",
      "ë³‘ì› ê¸°ë¡: Name:  ___                 Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Sulfa (Sulfonamide Anti...\n",
      "--------------------------------------------------------------------------------\n",
      "=== ê³ í’ˆì§ˆ ì˜ˆì‹œ 5 (ì ìˆ˜: 15) ===\n",
      "ICD ê°œìˆ˜: 3, ì¹´í…Œê³ ë¦¬: 3\n",
      "ICD ì½”ë“œ: ['D72829', 'J189', 'R509']\n",
      "í…ìŠ¤íŠ¸ ê¸¸ì´: 5353ì\n",
      "ë³‘ì› ê¸°ë¡: Name:  ___                     Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   M\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "ACE Inhibitors / al...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== SIMPLE ë³µì¡ë„ ì˜ˆì‹œ ===\n",
      "            parsed_icd  complexity_score\n",
      "5   [S066X1A, W1830XA]             8.365\n",
      "21              [E236]             6.227\n",
      "\n",
      "=== MEDIUM ë³µì¡ë„ ì˜ˆì‹œ ===\n",
      "  parsed_icd  complexity_score\n",
      "2     [I214]            11.524\n",
      "3     [R509]             9.387\n",
      "\n",
      "=== COMPLEX ë³µì¡ë„ ì˜ˆì‹œ ===\n",
      "             parsed_icd  complexity_score\n",
      "0  [I82431, K7581, N19]            19.269\n",
      "1        [I4891, M5440]            15.683\n",
      "\n",
      "ìƒìœ„ 20ê°œ ICD ì½”ë“œ: ['R079', 'R0600', 'I509', 'W1830XA', 'R4182', 'R531', 'I214', 'I4891', 'R51', 'R509']...\n",
      "                                        parsed_icd  common_code_count\n",
      "107  [I4891, K5732, N390, R4182, S065X0A, W050XXA]                  4\n",
      "386               [I214, L03116, N390, R079, R531]                  4\n",
      "595                      [I509, N179, R0600, R079]                  4\n",
      "96                      [I509, R0600, R0602, R531]                  3\n",
      "282                      [R4182, S065X0A, W1830XA]                  3\n"
     ]
    }
   ],
   "source": [
    "# Task C ë°ì´í„° ë¶„ì„ ë° Few-shot ì˜ˆì‹œ ì¶”ì¶œ\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def analyze_taskc_for_optimal_examples(train_csv_path: str):\n",
    "    \"\"\"Task C ìµœì  Few-shot ì˜ˆì‹œ ë¶„ì„ ë° ì¶”ì¶œ\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(train_csv_path)\n",
    "    print(f\"ì „ì²´ ë°ì´í„°: {len(df)}ê°œ\")\n",
    "    \n",
    "    # ê¸°ë³¸ í†µê³„\n",
    "    df = df.dropna(subset=['hospital_course', 'target'])\n",
    "    print(f\"ìœ íš¨ ë°ì´í„°: {len(df)}ê°œ\")\n",
    "    \n",
    "    # ICD ì½”ë“œ íŒŒì‹± ë° ë¶„ì„\n",
    "    def parse_icd_codes(icd_string):\n",
    "        if pd.isna(icd_string) or not isinstance(icd_string, str):\n",
    "            return []\n",
    "        \n",
    "        if icd_string.startswith('[') and icd_string.endswith(']'):\n",
    "            codes = icd_string.strip('[]').replace(\"'\", \"\").replace('\"', '').split(',')\n",
    "        else:\n",
    "            codes = re.split('[,\\s]+', icd_string)\n",
    "        \n",
    "        return [code.strip().upper() for code in codes if code.strip()]\n",
    "    \n",
    "    df['parsed_icd'] = df['target'].apply(parse_icd_codes)\n",
    "    df['icd_count'] = df['parsed_icd'].apply(len)\n",
    "    df['text_length'] = df['hospital_course'].str.len()\n",
    "    df['word_count'] = df['hospital_course'].str.split().str.len()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ê¸°ë³¸ í†µê³„:\")\n",
    "    print(f\"ICD ì½”ë“œ ê°œìˆ˜: í‰ê·  {df['icd_count'].mean():.1f}, ë²”ìœ„ {df['icd_count'].min()}-{df['icd_count'].max()}\")\n",
    "    print(f\"í…ìŠ¤íŠ¸ ê¸¸ì´: í‰ê·  {df['text_length'].mean():.0f}ì, ë²”ìœ„ {df['text_length'].min()}-{df['text_length'].max()}\")\n",
    "    print(f\"ë‹¨ì–´ ìˆ˜: í‰ê·  {df['word_count'].mean():.0f}ê°œ, ë²”ìœ„ {df['word_count'].min()}-{df['word_count'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_high_quality_icd_examples(df, top_n=20):\n",
    "    \"\"\"ICD ì½”ë”© ê³ í’ˆì§ˆ ì˜ˆì‹œ ì¶”ì¶œ\"\"\"\n",
    "    \n",
    "    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\n",
    "    df['quality_score'] = 0\n",
    "    \n",
    "    # 1. ì ì ˆí•œ ICD ê°œìˆ˜ (2-5ê°œê°€ í•™ìŠµì— ìµœì )\n",
    "    optimal_icd_count = (df['icd_count'] >= 2) & (df['icd_count'] <= 6)\n",
    "    df.loc[optimal_icd_count, 'quality_score'] += 5\n",
    "    \n",
    "    # 2. ì ì ˆí•œ í…ìŠ¤íŠ¸ ê¸¸ì´ (1000-8000ì, í•™ìŠµì— ì í•©)\n",
    "    optimal_length = (df['text_length'] >= 1000) & (df['text_length'] <= 8000)\n",
    "    df.loc[optimal_length, 'quality_score'] += 3\n",
    "    \n",
    "    # 3. ëª…í™•í•œ ì§„ë‹¨ëª… ì–¸ê¸‰ (Chief Complaint ë¶„ì„)\n",
    "    clear_diagnosis = df['hospital_course'].str.contains('Chief Complaint:', na=False)\n",
    "    df.loc[clear_diagnosis, 'quality_score'] += 2\n",
    "    \n",
    "    # 4. ë‹¤ì–‘í•œ ICD ì¹´í…Œê³ ë¦¬ í¬í•¨\n",
    "    def get_icd_categories(icd_list):\n",
    "        categories = set()\n",
    "        for code in icd_list:\n",
    "            if code:\n",
    "                categories.add(code[0])  # ì²« ë²ˆì§¸ ë¬¸ìë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\n",
    "        return len(categories)\n",
    "    \n",
    "    df['icd_categories'] = df['parsed_icd'].apply(get_icd_categories)\n",
    "    diverse_categories = df['icd_categories'] >= 2\n",
    "    df.loc[diverse_categories, 'quality_score'] += 3\n",
    "    \n",
    "    # 5. êµ¬ì¡°í™”ëœ ì˜ë£Œ ê¸°ë¡ (Past Medical History ë“±)\n",
    "    structured = df['hospital_course'].str.contains('Past Medical History|Physical Exam|History of Present Illness', na=False)\n",
    "    df.loc[structured, 'quality_score'] += 2\n",
    "    \n",
    "    # ìƒìœ„ ì˜ˆì‹œ ì„ íƒ\n",
    "    top_examples = df.nlargest(top_n, 'quality_score')\n",
    "    \n",
    "    return top_examples[['hospital_course', 'parsed_icd', 'quality_score', \n",
    "                        'icd_count', 'icd_categories', 'text_length']]\n",
    "\n",
    "def extract_examples_by_complexity(df, n_each=5):\n",
    "    \"\"\"ë³µì¡ë„ë³„ ì˜ˆì‹œ ì¶”ì¶œ (ë‹¨ìˆœ/ì¤‘ê°„/ë³µì¡)\"\"\"\n",
    "    \n",
    "    # ë³µì¡ë„ ê¸°ì¤€: ICD ê°œìˆ˜ + í…ìŠ¤íŠ¸ ê¸¸ì´ + ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„±\n",
    "    df['complexity_score'] = (\n",
    "        df['icd_count'] * 2 +\n",
    "        (df['text_length'] / 1000) +\n",
    "        df['icd_categories'] * 1.5\n",
    "    )\n",
    "    \n",
    "    # 3ë¶„ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "    percentiles = df['complexity_score'].quantile([0.33, 0.67]).values\n",
    "    \n",
    "    simple = df[df['complexity_score'] <= percentiles[0]]\n",
    "    medium = df[(df['complexity_score'] > percentiles[0]) & \n",
    "               (df['complexity_score'] <= percentiles[1])]\n",
    "    complex = df[df['complexity_score'] > percentiles[1]]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for category, subset in [('simple', simple), ('medium', medium), ('complex', complex)]:\n",
    "        if len(subset) > 0:\n",
    "            # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ ì„ íƒ\n",
    "            subset = subset.copy()\n",
    "            subset['quality_score'] = 0\n",
    "            \n",
    "            # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜ ì¬ê³„ì‚°\n",
    "            optimal_icd = (subset['icd_count'] >= 1) & (subset['icd_count'] <= 8)\n",
    "            subset.loc[optimal_icd, 'quality_score'] += 3\n",
    "            \n",
    "            clear_structure = subset['hospital_course'].str.contains('Chief Complaint|History of Present', na=False)\n",
    "            subset.loc[clear_structure, 'quality_score'] += 2\n",
    "            \n",
    "            top_subset = subset.nlargest(n_each, 'quality_score')\n",
    "            results[category] = top_subset[['hospital_course', 'parsed_icd', 'complexity_score', 'quality_score']]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def extract_common_icd_patterns(df, top_n=15):\n",
    "    \"\"\"ìì£¼ ë“±ì¥í•˜ëŠ” ICD íŒ¨í„´ ì˜ˆì‹œ ì¶”ì¶œ\"\"\"\n",
    "    \n",
    "    # ëª¨ë“  ICD ì½”ë“œ ìˆ˜ì§‘\n",
    "    all_codes = []\n",
    "    for icd_list in df['parsed_icd']:\n",
    "        all_codes.extend(icd_list)\n",
    "    \n",
    "    # ë¹ˆë„ ë¶„ì„\n",
    "    code_counts = Counter(all_codes)\n",
    "    common_codes = [code for code, count in code_counts.most_common(20)]\n",
    "    \n",
    "    print(f\"\\nìƒìœ„ 20ê°œ ICD ì½”ë“œ: {common_codes[:10]}...\")\n",
    "    \n",
    "    # ê³µí†µ ì½”ë“œ í¬í•¨ ì˜ˆì‹œ ì„ ë³„\n",
    "    def has_common_codes(icd_list):\n",
    "        return len(set(icd_list) & set(common_codes))\n",
    "    \n",
    "    df['common_code_count'] = df['parsed_icd'].apply(has_common_codes)\n",
    "    \n",
    "    # ê³µí†µ ì½”ë“œë¥¼ ë§ì´ í¬í•¨í•˜ë©´ì„œ í’ˆì§ˆ ì¢‹ì€ ì˜ˆì‹œ ì„ íƒ\n",
    "    df['pattern_score'] = df['common_code_count'] * 2 + df['quality_score']\n",
    "    \n",
    "    top_patterns = df.nlargest(top_n, 'pattern_score')\n",
    "    \n",
    "    return top_patterns[['hospital_course', 'parsed_icd', 'common_code_count', 'pattern_score']]\n",
    "\n",
    "# 1. ì „ì²´ ë°ì´í„° ë¶„ì„\n",
    "df = analyze_taskc_for_optimal_examples('./data/taskC_train.csv')\n",
    "\n",
    "# 2. ê³ í’ˆì§ˆ ì˜ˆì‹œ ì¶”ì¶œ (ìƒìœ„ 15ê°œ)\n",
    "high_quality = extract_high_quality_icd_examples(df, top_n=15)\n",
    "for i, (_, row) in enumerate(high_quality.head(5).iterrows()):\n",
    "    print(f'=== ê³ í’ˆì§ˆ ì˜ˆì‹œ {i+1} (ì ìˆ˜: {row[\"quality_score\"]}) ===')\n",
    "    print(f'ICD ê°œìˆ˜: {len(row[\"parsed_icd\"])}, ì¹´í…Œê³ ë¦¬: {row[\"icd_categories\"]}')\n",
    "    print(f'ICD ì½”ë“œ: {row[\"parsed_icd\"]}')\n",
    "    print(f'í…ìŠ¤íŠ¸ ê¸¸ì´: {row[\"text_length\"]}ì')\n",
    "    print(f'ë³‘ì› ê¸°ë¡: {row[\"hospital_course\"][:200]}...')\n",
    "    print('-' * 80)\n",
    "\n",
    "# 3. ë³µì¡ë„ë³„ ì˜ˆì‹œ\n",
    "by_complexity = extract_examples_by_complexity(df, n_each=3)\n",
    "for complexity, examples in by_complexity.items():\n",
    "    print(f'\\n=== {complexity.upper()} ë³µì¡ë„ ì˜ˆì‹œ ===')\n",
    "    print(examples[['parsed_icd', 'complexity_score']].head(2))\n",
    "\n",
    "# 4. ê³µí†µ íŒ¨í„´ ì˜ˆì‹œ\n",
    "common_patterns = extract_common_icd_patterns(df, top_n=10)\n",
    "print(common_patterns[['parsed_icd', 'common_code_count']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64190b58",
   "metadata": {},
   "source": [
    "## í”„ë¡¬í”„íŒ… ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "754406db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskCProcessor(DatathonProcessor):\n",
    "    \"\"\"Task C: ICD ì½”ë“œ ì˜ˆì¸¡\"\"\"\n",
    "    def get_model_name(self) -> str:\n",
    "        return \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\"  # ICD ì½”ë”©ì— ìµœì \n",
    "    \n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"You are an expert medical coder with 10+ years of experience in ICD-10 coding. Analyze the hospital course and assign the most appropriate ICD-10 codes.\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Focus on PRIMARY diagnoses and significant conditions only\n",
    "- Use exact ICD-10 format (e.g., I82431, S066X1A)\n",
    "- Maintain consistent coding standards regardless of patient demographics\n",
    "- Prioritize conditions that required active treatment during admission\n",
    "- Consider hierarchical relationships in ICD-10 classification\n",
    "\n",
    "CODING METHODOLOGY:\n",
    "1. Identify Chief Complaint and primary reason for admission\n",
    "2. Extract documented diagnoses from medical record\n",
    "3. Prioritize active conditions over chronic stable conditions\n",
    "4. Apply appropriate specificity and laterality codes\n",
    "5. Include significant complications or comorbidities\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "HOSPITAL COURSE: Patient with traumatic brain injury following fall...\n",
    "Service: NEUROSURGERY\n",
    "Chief Complaint: Head trauma\n",
    "History: Fall from ladder with loss of consciousness...\n",
    "Physical Exam: GCS 14, focal neurological deficits...\n",
    "Imaging: CT head shows subdural hematoma...\n",
    "CODES: S066X1A, W1830XA\n",
    "\n",
    "HOSPITAL COURSE: Elderly female with urinary retention and back pain...  \n",
    "Service: MEDICINE\n",
    "Chief Complaint: Unable to urinate, back pain\n",
    "History: Progressive back pain over 2 weeks, now with urinary retention...\n",
    "Past Medical History: Osteoporosis, hypertension...\n",
    "MRI: Lumbar spinal stenosis at L4-5...\n",
    "CODES: M5489, R339\n",
    "\n",
    "HOSPITAL COURSE: Middle-aged male presents with acute chest pain...\n",
    "Service: NEUROSURGERY  \n",
    "Chief Complaint: Sudden severe headache\n",
    "History: Sudden onset worst headache of life, found down at home...\n",
    "CT: Subarachnoid hemorrhage, no aneurysm identified...\n",
    "CODES: I609, R001\n",
    "\n",
    "HOSPITAL COURSE: Young female with psychiatric history presents with overdose...\n",
    "Service: MEDICINE\n",
    "Chief Complaint: Intentional overdose\n",
    "History: Depression with medication overdose, found by roommate...\n",
    "Toxicology: Elevated drug levels consistent with overdose...\n",
    "Psychiatry: Adjustment of medications, safety planning...\n",
    "CODES: F308, T380X5A, Y9289\n",
    "\n",
    "HOSPITAL COURSE: Male patient with fever and respiratory symptoms...\n",
    "Service: MEDICINE  \n",
    "Chief Complaint: Fever, shortness of breath\n",
    "History: 3-day history of fever, cough, dyspnea...\n",
    "Labs: Elevated WBC, abnormal inflammatory markers...\n",
    "CXR: Bilateral infiltrates consistent with pneumonia...\n",
    "CODES: D72829, J189, R509\n",
    "\n",
    "Now analyze this hospital course and provide ICD-10 codes:\n",
    "\n",
    "HOSPITAL COURSE: {user_input}\n",
    "\n",
    "CODES:\"\"\"\n",
    "\n",
    "    async def preprocess_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"ë³‘ì› ê¸°ë¡ì„ ICD ì½”ë”©ì„ ìœ„í•´ ì „ì²˜ë¦¬\"\"\"\n",
    "        import re\n",
    "        \n",
    "        hospital_course = data['hospital_course']\n",
    "        \n",
    "        # NaN ì²˜ë¦¬\n",
    "        if pd.isna(hospital_course) or not isinstance(hospital_course, str):\n",
    "            return {'user_input': ''}\n",
    "        \n",
    "        # í•µì‹¬ ì„¹ì…˜ ì¶”ì¶œ ë° ì •ë¦¬ (ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ìµœì í™”)\n",
    "        # ì¤‘ìš” ì„¹ì…˜ ìš°ì„  ì¶”ì¶œ\n",
    "        important_sections = []\n",
    "        \n",
    "        # Chief Complaint ì¶”ì¶œ\n",
    "        if 'Chief Complaint:' in hospital_course:\n",
    "            cc_match = re.search(r'Chief Complaint:\\s*([^\\n]+)', hospital_course)\n",
    "            if cc_match:\n",
    "                important_sections.append(f\"Chief Complaint: {cc_match.group(1).strip()}\")\n",
    "        \n",
    "        # Service ì¶”ì¶œ\n",
    "        if 'Service:' in hospital_course:\n",
    "            service_match = re.search(r'Service:\\s*([^\\n]+)', hospital_course)\n",
    "            if service_match:\n",
    "                important_sections.append(f\"Service: {service_match.group(1).strip()}\")\n",
    "        \n",
    "        # History of Present Illness ì¶”ì¶œ (ì²˜ìŒ 500ìë§Œ)\n",
    "        if 'History of Present Illness:' in hospital_course:\n",
    "            hpi_match = re.search(r'History of Present Illness:\\s*(.*?)(?=\\n\\n|\\nPast Medical|$)', \n",
    "                                hospital_course, re.DOTALL)\n",
    "            if hpi_match:\n",
    "                hpi = hpi_match.group(1).strip()[:500]  # ê¸¸ì´ ì œí•œ\n",
    "                important_sections.append(f\"History: {hpi}\")\n",
    "        \n",
    "        # Past Medical History ì¶”ì¶œ (ì¤‘ìš” ì§„ë‹¨ë§Œ)\n",
    "        if 'Past Medical History:' in hospital_course:\n",
    "            pmh_match = re.search(r'Past Medical History:\\s*(.*?)(?=\\n\\n|PAST SURGICAL|Social History|$)',\n",
    "                                hospital_course, re.DOTALL)\n",
    "            if pmh_match:\n",
    "                pmh = pmh_match.group(1).strip()[:300]  # ê¸¸ì´ ì œí•œ\n",
    "                important_sections.append(f\"Past Medical History: {pmh}\")\n",
    "        \n",
    "        # Physical Exam í•µì‹¬ ì†Œê²¬ë§Œ\n",
    "        if 'Physical Exam:' in hospital_course:\n",
    "            pe_match = re.search(r'ADMISSION PHYSICAL EXAM:\\s*(.*?)(?=DISCHARGE|Pertinent|$)',\n",
    "                               hospital_course, re.DOTALL)\n",
    "            if pe_match:\n",
    "                pe = pe_match.group(1).strip()[:400]  # ê¸¸ì´ ì œí•œ\n",
    "                important_sections.append(f\"Physical Exam: {pe}\")\n",
    "        \n",
    "        # Imaging ê²°ê³¼ (IMPRESSIONë§Œ)\n",
    "        impressions = re.findall(r'IMPRESSION:\\s*(.*?)(?=\\n\\n|\\n[A-Z_]|\\Z)', hospital_course, re.DOTALL)\n",
    "        if impressions:\n",
    "            for i, imp in enumerate(impressions[:2]):  # ìµœëŒ€ 2ê°œë§Œ\n",
    "                important_sections.append(f\"Imaging {i+1}: {imp.strip()[:200]}\")\n",
    "        \n",
    "        # ìµœì¢… í…ìŠ¤íŠ¸ êµ¬ì„± (ìµœëŒ€ 2000ìë¡œ ì œí•œ)\n",
    "        processed_text = '\\n\\n'.join(important_sections)\n",
    "        \n",
    "        # ë¶ˆí•„ìš”í•œ ì •ë³´ ì œê±°\n",
    "        processed_text = re.sub(r'___+', '[REDACTED]', processed_text)\n",
    "        processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
    "        processed_text = processed_text[:2000]  # ìµœëŒ€ ê¸¸ì´ ì œí•œ\n",
    "        \n",
    "        return {'user_input': processed_text.strip()}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        \"\"\"ICD ì½”ë“œ ê²°ê³¼ ì •ë¦¬ ë° í˜•ì‹í™”\"\"\"\n",
    "        import re\n",
    "        \n",
    "        result = result.strip()\n",
    "        \n",
    "        # \"CODES:\" ì œê±°\n",
    "        if result.startswith(('CODES:', 'codes:', 'Codes:')):\n",
    "            result = result.split(':', 1)[1].strip()\n",
    "        \n",
    "        # ICD ì½”ë“œë§Œ ì¶”ì¶œ (ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­)\n",
    "        # ICD-10 íŒ¨í„´: ë¬¸ì 1ê°œ + ìˆ«ì 2ê°œ + ì˜µì…˜(ë¬¸ììˆ«ì í˜¼í•©)\n",
    "        icd_pattern = r'[A-Z]\\d{2}[A-Z0-9]*'\n",
    "        \n",
    "        # ì‰¼í‘œ, ê³µë°±, ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ëœ ì½”ë“œë“¤ ì°¾ê¸°\n",
    "        codes = re.findall(icd_pattern, result.upper())\n",
    "        \n",
    "        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬\n",
    "        unique_codes = list(dict.fromkeys(codes))  # ìˆœì„œ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°\n",
    "        \n",
    "        # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬\n",
    "        if not unique_codes:\n",
    "            # ì›ë³¸ ê²°ê³¼ì—ì„œ ì•ŒíŒŒë²³+ìˆ«ì íŒ¨í„´ ì¬ì‹œë„\n",
    "            fallback_pattern = r'[A-Z]+\\d+[A-Z0-9]*'\n",
    "            codes = re.findall(fallback_pattern, result.upper())\n",
    "            unique_codes = list(dict.fromkeys(codes))[:3]  # ìµœëŒ€ 3ê°œ\n",
    "        \n",
    "        # ìµœëŒ€ 5ê°œ ì½”ë“œë¡œ ì œí•œ (ë°ì´í„° ë¶„ì„ ê²°ê³¼ í‰ê·  1.6ê°œ)\n",
    "        final_codes = unique_codes[:5]\n",
    "        \n",
    "        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ì½”ë“œ ë°˜í™˜\n",
    "        if not final_codes:\n",
    "            return 'Z515'  # Encounter for other aftercare\n",
    "        \n",
    "        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ ë°˜í™˜\n",
    "        return ', '.join(final_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a4df5",
   "metadata": {},
   "source": [
    "## ìì²´ í‰ê°€(EXAONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e07dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ† Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹œë®¬ë ˆì´ì…˜\n",
      "================================================================================\n",
      "1. ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "í‰ê°€ ìƒ˜í”Œ: 300ê°œ\n",
      "\n",
      "ğŸ“Š ë°ì´í„° ë¶„í¬:\n",
      "ì„±ë³„: {'M': 155, 'F': 145}\n",
      "ì—°ë ¹: í‰ê·  63.4ì„¸\n",
      "\n",
      "2. TaskC ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (EXAONE ëª¨ë¸)...\n",
      "3. ICD ì½”ë“œ ì˜ˆì¸¡ ìƒì„± ì¤‘...\n",
      "   ë°°ì¹˜ 1/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 2/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 3/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 4/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 5/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 6/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 7/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 8/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 9/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 10/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 11/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 12/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 13/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 14/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 15/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 16/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 17/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 18/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 19/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 20/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 21/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 22/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 23/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 24/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 25/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 26/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 27/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 28/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 29/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 30/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 31/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 32/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 33/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 34/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 35/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 36/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 37/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 38/38 ì²˜ë¦¬ ì¤‘...\n",
      "ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: 4100.0ì´ˆ)\n",
      "\n",
      "4. ICD ì½”ë“œ íŒŒì‹± ì¤‘...\n",
      "íŒŒì‹± ì™„ë£Œ: ì •ë‹µ 300ê°œ, ì˜ˆì¸¡ 300ê°œ\n",
      "5. ICDScore ê³„ì‚° ì¤‘...\n",
      "6. ê³µì •ì„± ì§€í‘œ ê³„ì‚° ì¤‘...\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ê²°ê³¼\n",
      "================================================================================\n",
      "ğŸ“Š ICDScore (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
      "   í‰ê· : 0.124441\n",
      "   í‘œì¤€í¸ì°¨: 0.126789\n",
      "   ìµœê³ : 0.571429\n",
      "   ìµœì €: 0.000000\n",
      "   ì¤‘ì•™ê°’: 0.095238\n",
      "\n",
      "âš–ï¸ ê³µì •ì„± ì§€í‘œ (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
      "   ì„±ë³„ ê³µì •ì„±: 0.858462\n",
      "   ì„±ë³„ë³„ ì„±ëŠ¥: {'F': 0.11467260927359449, 'M': 0.1335791988349592}\n",
      "   ì„±ë³„ ê²©ì°¨: 0.018907\n",
      "   \n",
      "   ì—°ë ¹ ê³µì •ì„±: 0.517571\n",
      "   ì—°ë ¹ëŒ€ë³„ ì„±ëŠ¥: {'10-20': 0.16666666666666669, '20-30': 0.09217687074829932, '30-40': 0.15631746031746033, '40-50': 0.17397959183673473, '50-60': 0.11678911564625853, '60-70': 0.10425697039379131, '70-80': 0.16346760926592857, '80-90': 0.11346377874617077, '90-100': 0.09004676870748299}\n",
      "   ì—°ë ¹ ê²©ì°¨: 0.083933\n",
      "\n",
      "ğŸ† Task C ì •ëŸ‰ í‰ê°€ ì ìˆ˜\n",
      "   ICDScore: 1.067/6.000 ì \n",
      "   ê³µì •ì„± ì§€í‘œ: 2.173/3.000 ì \n",
      "   ì •ëŸ‰ ì´ì : 3.239/9.000 ì \n",
      "   ì •ëŸ‰ ë‹¬ì„±ë¥ : 36.0%\n",
      "\n",
      "ğŸ–ï¸ ì„±ëŠ¥ ë“±ê¸‰\n",
      "   ë“±ê¸‰: Cê¸‰ (ë³´í†µ)\n",
      "   ê¶Œì¥ì‚¬í•­: ê°œì„  í•„ìš”\n",
      "\n",
      "ğŸ“ ì˜ˆì¸¡ í’ˆì§ˆ ìƒ˜í”Œ (ìƒìœ„/í•˜ìœ„ ê° 3ê°œ)\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ† ìµœê³  ì„±ëŠ¥ ìƒ˜í”Œ:\n",
      "ìƒ˜í”Œ 249 (ICDScore: 0.5714)\n",
      "ì •ë‹µ: ['I10', 'I609']\n",
      "ì˜ˆì¸¡: ['I609', 'R51', 'E10', 'E03', 'I10']\n",
      "\n",
      "ìƒ˜í”Œ 6 (ICDScore: 0.5000)\n",
      "ì •ë‹µ: ['R079']\n",
      "ì˜ˆì¸¡: ['R05']\n",
      "\n",
      "ìƒ˜í”Œ 11 (ICDScore: 0.5000)\n",
      "ì •ë‹µ: ['I609', 'R001']\n",
      "ì˜ˆì¸¡: ['I609', 'R51', 'Z73']\n",
      "\n",
      "âš ï¸ ìµœì € ì„±ëŠ¥ ìƒ˜í”Œ:\n",
      "ìƒ˜í”Œ 271 (ICDScore: 0.0000)\n",
      "ì •ë‹µ: ['H538']\n",
      "ì˜ˆì¸¡: ['I67', 'Z96', 'G94', 'I10', 'I609']\n",
      "\n",
      "ìƒ˜í”Œ 183 (ICDScore: 0.0000)\n",
      "ì •ë‹µ: ['R0600']\n",
      "ì˜ˆì¸¡: ['I49', 'J96', 'I50', 'I47', 'I10']\n",
      "\n",
      "ìƒ˜í”Œ 185 (ICDScore: 0.0000)\n",
      "ì •ë‹µ: ['C9112', 'R0600', 'R221']\n",
      "ì˜ˆì¸¡: ['I22', 'J96', 'K10', 'M15', 'I48']\n",
      "\n",
      "\n",
      "ğŸ‰ Task C ë¦¬ë”ë³´ë“œ í‰ê°€ ì™„ë£Œ!\n",
      "ìµœì¢… ì˜ˆìƒ ì ìˆ˜: 3.239/9.000 ì \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langevaluate.config import ModelConfig\n",
    "from langevaluate.llmfactory import LLMFactory\n",
    "import re\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ëŒ€íšŒ ì œê³µ ICDScore í´ë˜ìŠ¤ (100% ë™ì¼)\n",
    "def parse_icd_codes(icd_string: str) -> List[str]:\n",
    "    \"\"\"ICD ì½”ë“œ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\"\"\"\n",
    "    if not icd_string or pd.isna(icd_string):\n",
    "        return []\n",
    "    \n",
    "    if icd_string.startswith('[') and icd_string.endswith(']'):\n",
    "        codes = icd_string.strip('[]').replace(\"'\", \"\").replace('\"', '').split(',')\n",
    "    else:\n",
    "        codes = re.split('[,\\s]+', icd_string)\n",
    "    \n",
    "    cleaned_codes = [code.strip().upper() for code in codes if code.strip()]\n",
    "    return cleaned_codes\n",
    "\n",
    "def icd_similarity(code1: str, code2: str) -> float:\n",
    "    \"\"\"ICD-10 ê³„ì¸µ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    if not code1 or not code2:\n",
    "        return 0.0\n",
    "    \n",
    "    clean_code1 = code1.replace('.', '')\n",
    "    clean_code2 = code2.replace('.', '')\n",
    "    \n",
    "    max_len = min(len(clean_code1), len(clean_code2))\n",
    "    common = 0\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        if clean_code1[i] == clean_code2[i]:\n",
    "            common += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    max_depth = max(len(clean_code1), len(clean_code2))\n",
    "    return common / max_depth if max_depth > 0 else 0.0\n",
    "\n",
    "def hierarchical_f1(y_true: List[str], y_pred: List[str]) -> float:\n",
    "    \"\"\"ê³„ì¸µì  ë¶€ë¶„ ì ìˆ˜ë¥¼ ë°˜ì˜í•œ F1-score ê³„ì‚°\"\"\"\n",
    "    if len(y_true) == 0 and len(y_pred) == 0:\n",
    "        return 1.0\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    sim_matrix = np.zeros((len(y_true), len(y_pred)))\n",
    "    for i, true_code in enumerate(y_true):\n",
    "        for j, pred_code in enumerate(y_pred):\n",
    "            sim_matrix[i, j] = icd_similarity(true_code, pred_code)\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(-sim_matrix)\n",
    "    matched_score = sim_matrix[row_ind, col_ind].sum()\n",
    "    \n",
    "    partial_TP = matched_score\n",
    "    FP = len(y_pred) - partial_TP\n",
    "    FN = len(y_true) - partial_TP\n",
    "    \n",
    "    precision = partial_TP / len(y_pred) if len(y_pred) > 0 else 0\n",
    "    recall = partial_TP / len(y_true) if len(y_true) > 0 else 0\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "class ICDScore:\n",
    "    \"\"\"ICD-10 ê³„ì¸µì  F1-score í‰ê°€ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, refs: List[List[str]], hyps: List[List[str]]) -> List[float]:\n",
    "        if len(refs) != len(hyps):\n",
    "            raise ValueError(f\"ì°¸ì¡°ì™€ ì˜ˆì¸¡ ë°ì´í„°ì˜ ê¸¸ì´ê°€ ë‹¤ë¦…ë‹ˆë‹¤: {len(refs)} vs {len(hyps)}\")\n",
    "        \n",
    "        scores = []\n",
    "        for ref, hyp in zip(refs, hyps):\n",
    "            score = hierarchical_f1(ref, hyp)\n",
    "            scores.append(score)\n",
    "        \n",
    "        return scores\n",
    "\n",
    "# ëŒ€íšŒ ì œê³µ FairnessScore í´ë˜ìŠ¤ (100% ë™ì¼)\n",
    "class FairnessScore:\n",
    "    def __init__(self, bin_width: int = 10, min_samples_per_group: int = 1):\n",
    "        self.bin_width = int(bin_width)\n",
    "        self.min_samples_per_group = int(min_samples_per_group)\n",
    "        self.last_stats = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_1d(a) -> np.ndarray:\n",
    "        a = np.asarray(a)\n",
    "        if a.ndim == 2 and a.shape[1] == 1:\n",
    "            a = a[:, 0]\n",
    "        if a.ndim != 1:\n",
    "            raise ValueError(\"Input must be 1D or (N,1) shaped.\")\n",
    "        return a\n",
    "\n",
    "    def _bin_ages(self, ages) -> np.ndarray:\n",
    "        a = self._ensure_1d(ages).astype(float)\n",
    "        if np.any(np.isnan(a)):\n",
    "            raise ValueError(\"ages contain NaN.\")\n",
    "        if self.bin_width <= 0:\n",
    "            raise ValueError(\"bin_width must be positive.\")\n",
    "        starts = (np.floor(a / self.bin_width) * self.bin_width).astype(int)\n",
    "        ends = starts + self.bin_width\n",
    "        labels = np.array([f\"{s:d}-{e:d}\" for s, e in zip(starts, ends)], dtype=object)\n",
    "        return labels\n",
    "\n",
    "    def _groups_from_type(self, groups, type: str) -> np.ndarray:\n",
    "        t = (type or \"sex\").lower()\n",
    "        if t not in (\"sex\", \"age\"):\n",
    "            raise ValueError(\"type must be 'sex' or 'age'.\")\n",
    "        if t == \"sex\":\n",
    "            g = self._ensure_1d(groups)\n",
    "            return g\n",
    "        else:\n",
    "            return self._bin_ages(groups)\n",
    "\n",
    "    def __call__(self, groups, scores, type: str = \"sex\", sample_weight=None) -> float:\n",
    "        g = self._groups_from_type(groups, type=type)\n",
    "        s = self._ensure_1d(scores).astype(float)\n",
    "        if s.shape[0] != g.shape[0]:\n",
    "            raise ValueError(\"groups and scores must have the same length.\")\n",
    "\n",
    "        if sample_weight is None:\n",
    "            w = np.ones_like(s, dtype=float)\n",
    "        else:\n",
    "            w = self._ensure_1d(sample_weight).astype(float)\n",
    "            if w.shape[0] != s.shape[0]:\n",
    "                raise ValueError(\"sample_weight length must match scores.\")\n",
    "\n",
    "        s = np.clip(s, 0.0, 1.0)\n",
    "\n",
    "        uniq = np.unique(g)\n",
    "        means = []\n",
    "        by_group = {}\n",
    "        for grp in uniq:\n",
    "            mask = (g == grp)\n",
    "            if np.sum(mask) < self.min_samples_per_group:\n",
    "                continue\n",
    "            denom = np.sum(w[mask])\n",
    "            if denom <= 0:\n",
    "                continue\n",
    "            m = float(np.average(s[mask], weights=w[mask]))\n",
    "            means.append(m)\n",
    "            by_group[str(grp)] = m\n",
    "\n",
    "        if len(means) <= 1:\n",
    "            self.last_stats = {\"by_group\": by_group, \"gap\": 0.0, \"min\": None, \"max\": None}\n",
    "            return 1.0\n",
    "\n",
    "        max_m = float(np.max(means))\n",
    "        min_m = float(np.min(means))\n",
    "        fairness = 1.0 if max_m == 0.0 else float(min_m / max_m)\n",
    "        fairness = float(np.clip(fairness, 0.0, 1.0))\n",
    "\n",
    "        self.last_stats = {\"by_group\": by_group, \"gap\": max_m - min_m, \"min\": min_m, \"max\": max_m}\n",
    "        return fairness\n",
    "\n",
    "# TaskC Processor (ì•ì„œ ì‘ì„±í•œ ì½”ë“œ)\n",
    "class TaskCProcessor:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        \n",
    "        config = ModelConfig(\n",
    "            model_name=\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\",\n",
    "            # model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "            api_base=\"https://api.snubhai.org/api/v1/llm\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=2000,\n",
    "            seed=777,\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        self.llm = LLMFactory.create_llm(config, temperature=0, rpm=10)\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"You are an expert medical coder with 10+ years of experience in ICD-10 coding. Analyze the hospital course and assign the most appropriate ICD-10 codes.\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Focus on PRIMARY diagnoses and significant conditions only\n",
    "- Use exact ICD-10 format (e.g., I82431, S066X1A)\n",
    "- Maintain consistent coding standards regardless of patient demographics\n",
    "- Prioritize conditions that required active treatment during admission\n",
    "- Consider hierarchical relationships in ICD-10 classification\n",
    "\n",
    "CODING METHODOLOGY:\n",
    "1. Identify Chief Complaint and primary reason for admission\n",
    "2. Extract documented diagnoses from medical record\n",
    "3. Prioritize active conditions over chronic stable conditions\n",
    "4. Apply appropriate specificity and laterality codes\n",
    "5. Include significant complications or comorbidities\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "HOSPITAL COURSE: Patient with traumatic brain injury following fall...\n",
    "Service: NEUROSURGERY\n",
    "Chief Complaint: Head trauma\n",
    "History: Fall from ladder with loss of consciousness...\n",
    "Physical Exam: GCS 14, focal neurological deficits...\n",
    "Imaging: CT head shows subdural hematoma...\n",
    "CODES: S066X1A, W1830XA\n",
    "\n",
    "HOSPITAL COURSE: Elderly female with urinary retention and back pain...  \n",
    "Service: MEDICINE\n",
    "Chief Complaint: Unable to urinate, back pain\n",
    "History: Progressive back pain over 2 weeks, now with urinary retention...\n",
    "Past Medical History: Osteoporosis, hypertension...\n",
    "MRI: Lumbar spinal stenosis at L4-5...\n",
    "CODES: M5489, R339\n",
    "\n",
    "HOSPITAL COURSE: Middle-aged male presents with acute chest pain...\n",
    "Service: NEUROSURGERY  \n",
    "Chief Complaint: Sudden severe headache\n",
    "History: Sudden onset worst headache of life, found down at home...\n",
    "CT: Subarachnoid hemorrhage, no aneurysm identified...\n",
    "CODES: I609, R001\n",
    "\n",
    "Now analyze this hospital course and provide ICD-10 codes:\n",
    "\n",
    "HOSPITAL COURSE: {user_input}\n",
    "\n",
    "CODES:\"\"\"\n",
    "\n",
    "    async def preprocess_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        hospital_course = data['hospital_course']\n",
    "        \n",
    "        if pd.isna(hospital_course) or not isinstance(hospital_course, str):\n",
    "            return {'user_input': ''}\n",
    "        \n",
    "        important_sections = []\n",
    "        \n",
    "        # Chief Complaint ì¶”ì¶œ\n",
    "        if 'Chief Complaint:' in hospital_course:\n",
    "            cc_match = re.search(r'Chief Complaint:\\s*([^\\n]+)', hospital_course)\n",
    "            if cc_match:\n",
    "                important_sections.append(f\"Chief Complaint: {cc_match.group(1).strip()}\")\n",
    "        \n",
    "        # Service ì¶”ì¶œ\n",
    "        if 'Service:' in hospital_course:\n",
    "            service_match = re.search(r'Service:\\s*([^\\n]+)', hospital_course)\n",
    "            if service_match:\n",
    "                important_sections.append(f\"Service: {service_match.group(1).strip()}\")\n",
    "        \n",
    "        # History of Present Illness ì¶”ì¶œ\n",
    "        if 'History of Present Illness:' in hospital_course:\n",
    "            hpi_match = re.search(r'History of Present Illness:\\s*(.*?)(?=\\n\\n|\\nPast Medical|$)', \n",
    "                                hospital_course, re.DOTALL)\n",
    "            if hpi_match:\n",
    "                hpi = hpi_match.group(1).strip()[:500]\n",
    "                important_sections.append(f\"History: {hpi}\")\n",
    "        \n",
    "        # Past Medical History ì¶”ì¶œ\n",
    "        if 'Past Medical History:' in hospital_course:\n",
    "            pmh_match = re.search(r'Past Medical History:\\s*(.*?)(?=\\n\\n|PAST SURGICAL|Social History|$)',\n",
    "                                hospital_course, re.DOTALL)\n",
    "            if pmh_match:\n",
    "                pmh = pmh_match.group(1).strip()[:300]\n",
    "                important_sections.append(f\"Past Medical History: {pmh}\")\n",
    "        \n",
    "        # Imaging IMPRESSION ì¶”ì¶œ\n",
    "        impressions = re.findall(r'IMPRESSION:\\s*(.*?)(?=\\n\\n|\\n[A-Z_]|\\Z)', hospital_course, re.DOTALL)\n",
    "        if impressions:\n",
    "            for i, imp in enumerate(impressions[:2]):\n",
    "                important_sections.append(f\"Imaging {i+1}: {imp.strip()[:200]}\")\n",
    "        \n",
    "        processed_text = '\\n\\n'.join(important_sections)\n",
    "        processed_text = re.sub(r'___+', '[REDACTED]', processed_text)\n",
    "        processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
    "        processed_text = processed_text[:2000]\n",
    "        \n",
    "        return {'user_input': processed_text.strip()}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        result = result.strip()\n",
    "        \n",
    "        if result.startswith(('CODES:', 'codes:', 'Codes:')):\n",
    "            result = result.split(':', 1)[1].strip()\n",
    "        \n",
    "        icd_pattern = r'[A-Z]\\d{2}[A-Z0-9]*'\n",
    "        codes = re.findall(icd_pattern, result.upper())\n",
    "        unique_codes = list(dict.fromkeys(codes))\n",
    "        \n",
    "        if not unique_codes:\n",
    "            fallback_pattern = r'[A-Z]+\\d+[A-Z0-9]*'\n",
    "            codes = re.findall(fallback_pattern, result.upper())\n",
    "            unique_codes = list(dict.fromkeys(codes))[:3]\n",
    "        \n",
    "        final_codes = unique_codes[:5]\n",
    "        \n",
    "        if not final_codes:\n",
    "            return 'Z515'\n",
    "        \n",
    "        return ', '.join(final_codes)\n",
    "\n",
    "# ë¦¬ë”ë³´ë“œ ë™ì¼ í‰ê°€ í•¨ìˆ˜\n",
    "async def exact_taskc_evaluation(train_csv_path: str, api_key: str):\n",
    "    \"\"\"ëŒ€íšŒ ë¦¬ë”ë³´ë“œì™€ ì •í™•íˆ ë™ì¼í•œ Task C í‰ê°€\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ† Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹œë®¬ë ˆì´ì…˜\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    print(\"1. ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "    df = pd.read_csv(train_csv_path)\n",
    "    df = df.dropna(subset=['hospital_course', 'target'])\n",
    "    \n",
    "    eval_samples = min(300, len(df))\n",
    "    eval_df = df.iloc[:eval_samples].copy()\n",
    "    print(f\"í‰ê°€ ìƒ˜í”Œ: {eval_samples}ê°œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í¬:\")\n",
    "    print(f\"ì„±ë³„: {eval_df['gender'].value_counts().to_dict()}\")\n",
    "    print(f\"ì—°ë ¹: í‰ê·  {eval_df['anchor_age'].mean():.1f}ì„¸\")\n",
    "    \n",
    "    # 2. TaskC ì²˜ë¦¬ê¸° ì´ˆê¸°í™”\n",
    "    print(\"\\n2. TaskC ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (EXAONE ëª¨ë¸)...\")\n",
    "    processor = TaskCProcessor(api_key)\n",
    "    \n",
    "    # 3. ì˜ˆì¸¡ ìƒì„±\n",
    "    print(\"3. ICD ì½”ë“œ ì˜ˆì¸¡ ìƒì„± ì¤‘...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    data_batch = [{'hospital_course': row['hospital_course']} for _, row in eval_df.iterrows()]\n",
    "    \n",
    "    results = []\n",
    "    batch_size = 8\n",
    "    \n",
    "    for i in range(0, len(data_batch), batch_size):\n",
    "        batch = data_batch[i:i+batch_size]\n",
    "        print(f\"   ë°°ì¹˜ {i//batch_size + 1}/{(len(data_batch)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ì „ì²˜ë¦¬\n",
    "        preprocessed = [await processor.preprocess_data(row) for row in batch]\n",
    "        \n",
    "        # API í˜¸ì¶œ\n",
    "        tasks = [processor.chain.ainvoke(prep) for prep in preprocessed]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # í›„ì²˜ë¦¬\n",
    "        batch_results = [await processor.postprocess_result(r.content) for r in responses]\n",
    "        results.extend(batch_results)\n",
    "        \n",
    "        # API ì œí•œ ì¤€ìˆ˜\n",
    "        if i + batch_size < len(data_batch):\n",
    "            print(f\"   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\")\n",
    "            await asyncio.sleep(70)\n",
    "    \n",
    "    predictions = results\n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {generation_time:.1f}ì´ˆ)\")\n",
    "    \n",
    "    # 4. ì •ë‹µ ë°ì´í„° ì¤€ë¹„ (ëŒ€íšŒ í˜•ì‹ê³¼ ë™ì¼)\n",
    "    references = eval_df['target'].tolist()\n",
    "    \n",
    "    # ICD ì½”ë“œ íŒŒì‹± (ëŒ€íšŒ í‰ê°€ì™€ ë™ì¼)\n",
    "    print(\"\\n4. ICD ì½”ë“œ íŒŒì‹± ì¤‘...\")\n",
    "    ref_codes = [parse_icd_codes(ref) for ref in references]\n",
    "    pred_codes = [parse_icd_codes(pred) for pred in predictions]\n",
    "    \n",
    "    print(f\"íŒŒì‹± ì™„ë£Œ: ì •ë‹µ {len(ref_codes)}ê°œ, ì˜ˆì¸¡ {len(pred_codes)}ê°œ\")\n",
    "    \n",
    "    # 5. ICDScore ê³„ì‚° (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
    "    print(\"5. ICDScore ê³„ì‚° ì¤‘...\")\n",
    "    icd_scorer = ICDScore()\n",
    "    icd_scores = icd_scorer(refs=ref_codes, hyps=pred_codes)\n",
    "    icd_mean = np.mean(icd_scores)\n",
    "    icd_std = np.std(icd_scores)\n",
    "    \n",
    "    # 6. ê³µì •ì„± ì§€í‘œ ê³„ì‚° (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
    "    print(\"6. ê³µì •ì„± ì§€í‘œ ê³„ì‚° ì¤‘...\")\n",
    "    fairness_scorer = FairnessScore(bin_width=10, min_samples_per_group=1)\n",
    "    \n",
    "    # ì„±ë³„ ê³µì •ì„±\n",
    "    gender_fairness = fairness_scorer(\n",
    "        groups=eval_df['gender'].tolist(),\n",
    "        scores=icd_scores,\n",
    "        type='sex'\n",
    "    )\n",
    "    gender_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # ì—°ë ¹ ê³µì •ì„±\n",
    "    age_fairness = fairness_scorer(\n",
    "        groups=eval_df['anchor_age'].tolist(),\n",
    "        scores=icd_scores,\n",
    "        type='age'  \n",
    "    )\n",
    "    age_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # 7. ëŒ€íšŒ ì •í™•í•œ ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ¯ Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"ğŸ“Š ICDScore (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\")\n",
    "    print(f\"   í‰ê· : {icd_mean:.6f}\")\n",
    "    print(f\"   í‘œì¤€í¸ì°¨: {icd_std:.6f}\")\n",
    "    print(f\"   ìµœê³ : {max(icd_scores):.6f}\")\n",
    "    print(f\"   ìµœì €: {min(icd_scores):.6f}\")\n",
    "    print(f\"   ì¤‘ì•™ê°’: {np.median(icd_scores):.6f}\")\n",
    "    \n",
    "    print(f\"\\nâš–ï¸ ê³µì •ì„± ì§€í‘œ (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\")\n",
    "    print(f\"   ì„±ë³„ ê³µì •ì„±: {gender_fairness:.6f}\")\n",
    "    print(f\"   ì„±ë³„ë³„ ì„±ëŠ¥: {gender_stats['by_group']}\")\n",
    "    print(f\"   ì„±ë³„ ê²©ì°¨: {gender_stats['gap']:.6f}\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   ì—°ë ¹ ê³µì •ì„±: {age_fairness:.6f}\")\n",
    "    print(f\"   ì—°ë ¹ëŒ€ë³„ ì„±ëŠ¥: {age_stats['by_group']}\")\n",
    "    print(f\"   ì—°ë ¹ ê²©ì°¨: {age_stats['gap']:.6f}\")\n",
    "    \n",
    "    # 8. ì •ëŸ‰ í‰ê°€ ì ìˆ˜ ê³„ì‚° (Task CëŠ” 9ì  ë§Œì )\n",
    "    print(f\"\\nğŸ† Task C ì •ëŸ‰ í‰ê°€ ì ìˆ˜\")\n",
    "    \n",
    "    # ICDScore ì ìˆ˜ (6ì  ë§Œì  - 9ì ì˜ 2/3)\n",
    "    icd_score_points = min(6.0, max(0.0, (icd_mean / 0.70) * 6.0))  # ëª©í‘œ 0.70\n",
    "    \n",
    "    # ê³µì •ì„± ì ìˆ˜ (3ì  ë§Œì  - 9ì ì˜ 1/3)\n",
    "    fairness_avg = (gender_fairness + age_fairness) / 2.0\n",
    "    fairness_points = min(3.0, max(0.0, (fairness_avg / 0.95) * 3.0))\n",
    "    \n",
    "    # ì´ì \n",
    "    total_quantitative = icd_score_points + fairness_points\n",
    "    \n",
    "    print(f\"   ICDScore: {icd_score_points:.3f}/6.000 ì \")\n",
    "    print(f\"   ê³µì •ì„± ì§€í‘œ: {fairness_points:.3f}/3.000 ì \")\n",
    "    print(f\"   ì •ëŸ‰ ì´ì : {total_quantitative:.3f}/9.000 ì \")\n",
    "    print(f\"   ì •ëŸ‰ ë‹¬ì„±ë¥ : {total_quantitative/9.0*100:.1f}%\")\n",
    "    \n",
    "    # 9. ì„±ëŠ¥ ë“±ê¸‰ íŒì •\n",
    "    print(f\"\\nğŸ–ï¸ ì„±ëŠ¥ ë“±ê¸‰\")\n",
    "    if total_quantitative >= 7.5:\n",
    "        grade = \"Sê¸‰ (ìµœìš°ìˆ˜)\"\n",
    "        recommendation = \"ì¦‰ì‹œ ì œì¶œ ê¶Œì¥\"\n",
    "    elif total_quantitative >= 6.5:\n",
    "        grade = \"Aê¸‰ (ìš°ìˆ˜)\"\n",
    "        recommendation = \"ì œì¶œ ê¶Œì¥\"\n",
    "    elif total_quantitative >= 5.5:\n",
    "        grade = \"Bê¸‰ (ì–‘í˜¸)\"\n",
    "        recommendation = \"ì†Œí­ ê°œì„  í›„ ì œì¶œ\"\n",
    "    else:\n",
    "        grade = \"Cê¸‰ (ë³´í†µ)\"\n",
    "        recommendation = \"ê°œì„  í•„ìš”\"\n",
    "    \n",
    "    print(f\"   ë“±ê¸‰: {grade}\")\n",
    "    print(f\"   ê¶Œì¥ì‚¬í•­: {recommendation}\")\n",
    "    \n",
    "    # 10. ì˜ˆì¸¡ ìƒ˜í”Œ ë¶„ì„\n",
    "    print(f\"\\nğŸ“ ì˜ˆì¸¡ í’ˆì§ˆ ìƒ˜í”Œ (ìƒìœ„/í•˜ìœ„ ê° 3ê°œ)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    sorted_indices = np.argsort(icd_scores)\n",
    "    \n",
    "    print(\"ğŸ† ìµœê³  ì„±ëŠ¥ ìƒ˜í”Œ:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[-(i+1)]\n",
    "        print(f\"ìƒ˜í”Œ {idx} (ICDScore: {icd_scores[idx]:.4f})\")\n",
    "        print(f\"ì •ë‹µ: {ref_codes[idx]}\")\n",
    "        print(f\"ì˜ˆì¸¡: {pred_codes[idx]}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"âš ï¸ ìµœì € ì„±ëŠ¥ ìƒ˜í”Œ:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[i]\n",
    "        print(f\"ìƒ˜í”Œ {idx} (ICDScore: {icd_scores[idx]:.4f})\")\n",
    "        print(f\"ì •ë‹µ: {ref_codes[idx]}\")\n",
    "        print(f\"ì˜ˆì¸¡: {pred_codes[idx]}\")\n",
    "        print()\n",
    "    \n",
    "    return {\n",
    "        'icd_score_mean': icd_mean,\n",
    "        'icd_score_std': icd_std,\n",
    "        'icd_scores': icd_scores,\n",
    "        'gender_fairness': gender_fairness,\n",
    "        'age_fairness': age_fairness,\n",
    "        'total_score': total_quantitative,\n",
    "        'grade': grade,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'evaluation_samples': eval_samples,\n",
    "        'processing_time': generation_time\n",
    "    }\n",
    "\n",
    "# ì‹¤í–‰\n",
    "API_KEY = \"cfa06ca698c85aa9c9d4b55440aeef0f85ed94f644cd7b931fdd69f2421c6ecb\"\n",
    "TRAIN_CSV_PATH = \"./data/taskC_train.csv\"\n",
    "\n",
    "# Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹¤í–‰\n",
    "taskc_results = await exact_taskc_evaluation(\n",
    "    train_csv_path=TRAIN_CSV_PATH,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ‰ Task C ë¦¬ë”ë³´ë“œ í‰ê°€ ì™„ë£Œ!\")\n",
    "print(f\"ìµœì¢… ì˜ˆìƒ ì ìˆ˜: {taskc_results['total_score']:.3f}/9.000 ì \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac7da0",
   "metadata": {},
   "source": [
    "## ìì²´í‰ê°€(Llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a0758e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ† Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹œë®¬ë ˆì´ì…˜\n",
      "================================================================================\n",
      "1. ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "í‰ê°€ ìƒ˜í”Œ: 300ê°œ\n",
      "\n",
      "ğŸ“Š ë°ì´í„° ë¶„í¬:\n",
      "ì„±ë³„: {'M': 155, 'F': 145}\n",
      "ì—°ë ¹: í‰ê·  63.4ì„¸\n",
      "\n",
      "2. TaskC ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (EXAONE ëª¨ë¸)...\n",
      "3. ICD ì½”ë“œ ì˜ˆì¸¡ ìƒì„± ì¤‘...\n",
      "   ë°°ì¹˜ 1/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 2/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 3/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 4/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 5/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 6/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 7/38 ì²˜ë¦¬ ì¤‘...\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 8/38 ì²˜ë¦¬ ì¤‘...\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 9/38 ì²˜ë¦¬ ì¤‘...\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 10/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 11/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 12/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 13/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 14/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 15/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 16/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 17/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 18/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 19/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 20/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 21/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 22/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 23/38 ì²˜ë¦¬ ì¤‘...\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: Error code: 429 - {'error': {'message': 'Rate limit exceeded. Token bucket: 0.00/10.0 tokens. Wait 60s.', 'type': 'rate_limit_error', 'param': None, 'code': 'rate_limit_exceeded'}}, retry 1/3\n",
      "API Error: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "<title>snubhai.org | 504: Gateway time-out</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "                <span class=\"inline-block\">Gateway time-out</span>\n",
      "                <span class=\"code-label\">Error code 504</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "                Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.snubhai.org\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2025-09-24 18:13:33 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                    <div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "  \n",
      "    Browser\n",
      "  \n",
      "  </h3>\n",
      "  \n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "  \n",
      "</div>\n",
      "                    <div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&#38;utm_campaign=api.snubhai.org\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">Hong Kong</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "  <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.snubhai.org\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "  </a>\n",
      "  </h3>\n",
      "  \n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "  \n",
      "</div>\n",
      "                    <div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.snubhai.org</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "  \n",
      "    Host\n",
      "  \n",
      "  </h3>\n",
      "  \n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "  \n",
      "</div>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>The web server reported a gateway time-out error.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                    <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "    <p class=\"text-13\">\n",
      "      <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">9844402d3df1c8c3</strong></span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "      <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "        Your IP:\n",
      "        <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "        <span class=\"hidden\" id=\"cf-footer-ip\">115.138.60.244</span>\n",
      "        <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "      </span>\n",
      "      <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&#38;utm_campaign=api.snubhai.org\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "      \n",
      "    </p>\n",
      "    <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "  </div><!-- /.error-footer -->\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>, retry 2/3\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 24/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 25/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 26/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 27/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 28/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 29/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 30/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 31/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 32/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 33/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 34/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 35/38 ì²˜ë¦¬ ì¤‘...\n",
      "API Error: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "<title>snubhai.org | 504: Gateway time-out</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "                <span class=\"inline-block\">Gateway time-out</span>\n",
      "                <span class=\"code-label\">Error code 504</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "                Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.snubhai.org\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2025-09-24 18:41:24 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                    <div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "  \n",
      "    Browser\n",
      "  \n",
      "  </h3>\n",
      "  \n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "  \n",
      "</div>\n",
      "                    <div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&#38;utm_campaign=api.snubhai.org\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">Hong Kong</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "  <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.snubhai.org\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "  </a>\n",
      "  </h3>\n",
      "  \n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "  \n",
      "</div>\n",
      "                    <div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.snubhai.org</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "  \n",
      "    Host\n",
      "  \n",
      "  </h3>\n",
      "  \n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "  \n",
      "</div>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>The web server reported a gateway time-out error.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                    <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "    <p class=\"text-13\">\n",
      "      <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">984468f70ca20721</strong></span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "      <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "        Your IP:\n",
      "        <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "        <span class=\"hidden\" id=\"cf-footer-ip\">115.138.60.244</span>\n",
      "        <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "      </span>\n",
      "      <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&#38;utm_campaign=api.snubhai.org\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "      \n",
      "    </p>\n",
      "    <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "  </div><!-- /.error-footer -->\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>, retry 1/3\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 36/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 37/38 ì²˜ë¦¬ ì¤‘...\n",
      "   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\n",
      "   ë°°ì¹˜ 38/38 ì²˜ë¦¬ ì¤‘...\n",
      "ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: 6259.4ì´ˆ)\n",
      "\n",
      "4. ICD ì½”ë“œ íŒŒì‹± ì¤‘...\n",
      "íŒŒì‹± ì™„ë£Œ: ì •ë‹µ 300ê°œ, ì˜ˆì¸¡ 300ê°œ\n",
      "5. ICDScore ê³„ì‚° ì¤‘...\n",
      "6. ê³µì •ì„± ì§€í‘œ ê³„ì‚° ì¤‘...\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ê²°ê³¼\n",
      "================================================================================\n",
      "ğŸ“Š ICDScore (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
      "   í‰ê· : 0.134840\n",
      "   í‘œì¤€í¸ì°¨: 0.129713\n",
      "   ìµœê³ : 0.571429\n",
      "   ìµœì €: 0.000000\n",
      "   ì¤‘ì•™ê°’: 0.122449\n",
      "\n",
      "âš–ï¸ ê³µì •ì„± ì§€í‘œ (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
      "   ì„±ë³„ ê³µì •ì„±: 0.882380\n",
      "   ì„±ë³„ë³„ ì„±ëŠ¥: {'F': 0.1261516277008888, 'M': 0.14296752914264432}\n",
      "   ì„±ë³„ ê²©ì°¨: 0.016816\n",
      "   \n",
      "   ì—°ë ¹ ê³µì •ì„±: 0.000000\n",
      "   ì—°ë ¹ëŒ€ë³„ ì„±ëŠ¥: {'10-20': 0.0, '20-30': 0.13038548752834467, '30-40': 0.1633809523809524, '40-50': 0.17502551020408164, '50-60': 0.13054421768707483, '60-70': 0.13233560090702948, '70-80': 0.16311995168437746, '80-90': 0.08884580259164976, '90-100': 0.1283078231292517}\n",
      "   ì—°ë ¹ ê²©ì°¨: 0.175026\n",
      "\n",
      "ğŸ† Task C ì •ëŸ‰ í‰ê°€ ì ìˆ˜\n",
      "   ICDScore: 1.156/6.000 ì \n",
      "   ê³µì •ì„± ì§€í‘œ: 1.393/3.000 ì \n",
      "   ì •ëŸ‰ ì´ì : 2.549/9.000 ì \n",
      "   ì •ëŸ‰ ë‹¬ì„±ë¥ : 28.3%\n",
      "\n",
      "ğŸ–ï¸ ì„±ëŠ¥ ë“±ê¸‰\n",
      "   ë“±ê¸‰: Cê¸‰ (ë³´í†µ)\n",
      "   ê¶Œì¥ì‚¬í•­: ê°œì„  í•„ìš”\n",
      "\n",
      "ğŸ“ ì˜ˆì¸¡ í’ˆì§ˆ ìƒ˜í”Œ (ìƒìœ„/í•˜ìœ„ ê° 3ê°œ)\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ† ìµœê³  ì„±ëŠ¥ ìƒ˜í”Œ:\n",
      "ìƒ˜í”Œ 249 (ICDScore: 0.5714)\n",
      "ì •ë‹µ: ['I10', 'I609']\n",
      "ì˜ˆì¸¡: ['I609', 'I10', 'E11', 'E03', 'K21']\n",
      "\n",
      "ìƒ˜í”Œ 279 (ICDScore: 0.5714)\n",
      "ì •ë‹µ: ['R55', 'S0211GA', 'S065X9A', 'W1830XA']\n",
      "ì˜ˆì¸¡: ['S06', 'S02', 'W18', 'R55']\n",
      "\n",
      "ìƒ˜í”Œ 140 (ICDScore: 0.5625)\n",
      "ì •ë‹µ: ['I440', 'R002', 'R55']\n",
      "ì˜ˆì¸¡: ['I47', 'R00', 'R55', 'F41', 'D58']\n",
      "\n",
      "âš ï¸ ìµœì € ì„±ëŠ¥ ìƒ˜í”Œ:\n",
      "ìƒ˜í”Œ 200 (ICDScore: 0.0000)\n",
      "ì •ë‹µ: ['R55']\n",
      "ì˜ˆì¸¡: ['I48', 'I71', 'I10', 'E78', 'J44']\n",
      "\n",
      "ìƒ˜í”Œ 236 (ICDScore: 0.0000)\n",
      "ì •ë‹µ: ['R4182']\n",
      "ì˜ˆì¸¡: ['S06', 'I63', 'I10', 'W18']\n",
      "\n",
      "ìƒ˜í”Œ 139 (ICDScore: 0.0000)\n",
      "ì •ë‹µ: ['I213']\n",
      "ì˜ˆì¸¡: ['R10', 'R07', 'Z85']\n",
      "\n",
      "\n",
      "ğŸ‰ Task C ë¦¬ë”ë³´ë“œ í‰ê°€ ì™„ë£Œ!\n",
      "ìµœì¢… ì˜ˆìƒ ì ìˆ˜: 2.549/9.000 ì \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langevaluate.config import ModelConfig\n",
    "from langevaluate.llmfactory import LLMFactory\n",
    "import re\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ëŒ€íšŒ ì œê³µ ICDScore í´ë˜ìŠ¤ (100% ë™ì¼)\n",
    "def parse_icd_codes(icd_string: str) -> List[str]:\n",
    "    \"\"\"ICD ì½”ë“œ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\"\"\"\n",
    "    if not icd_string or pd.isna(icd_string):\n",
    "        return []\n",
    "    \n",
    "    if icd_string.startswith('[') and icd_string.endswith(']'):\n",
    "        codes = icd_string.strip('[]').replace(\"'\", \"\").replace('\"', '').split(',')\n",
    "    else:\n",
    "        codes = re.split('[,\\s]+', icd_string)\n",
    "    \n",
    "    cleaned_codes = [code.strip().upper() for code in codes if code.strip()]\n",
    "    return cleaned_codes\n",
    "\n",
    "def icd_similarity(code1: str, code2: str) -> float:\n",
    "    \"\"\"ICD-10 ê³„ì¸µ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    if not code1 or not code2:\n",
    "        return 0.0\n",
    "    \n",
    "    clean_code1 = code1.replace('.', '')\n",
    "    clean_code2 = code2.replace('.', '')\n",
    "    \n",
    "    max_len = min(len(clean_code1), len(clean_code2))\n",
    "    common = 0\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        if clean_code1[i] == clean_code2[i]:\n",
    "            common += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    max_depth = max(len(clean_code1), len(clean_code2))\n",
    "    return common / max_depth if max_depth > 0 else 0.0\n",
    "\n",
    "def hierarchical_f1(y_true: List[str], y_pred: List[str]) -> float:\n",
    "    \"\"\"ê³„ì¸µì  ë¶€ë¶„ ì ìˆ˜ë¥¼ ë°˜ì˜í•œ F1-score ê³„ì‚°\"\"\"\n",
    "    if len(y_true) == 0 and len(y_pred) == 0:\n",
    "        return 1.0\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    sim_matrix = np.zeros((len(y_true), len(y_pred)))\n",
    "    for i, true_code in enumerate(y_true):\n",
    "        for j, pred_code in enumerate(y_pred):\n",
    "            sim_matrix[i, j] = icd_similarity(true_code, pred_code)\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(-sim_matrix)\n",
    "    matched_score = sim_matrix[row_ind, col_ind].sum()\n",
    "    \n",
    "    partial_TP = matched_score\n",
    "    FP = len(y_pred) - partial_TP\n",
    "    FN = len(y_true) - partial_TP\n",
    "    \n",
    "    precision = partial_TP / len(y_pred) if len(y_pred) > 0 else 0\n",
    "    recall = partial_TP / len(y_true) if len(y_true) > 0 else 0\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "class ICDScore:\n",
    "    \"\"\"ICD-10 ê³„ì¸µì  F1-score í‰ê°€ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, refs: List[List[str]], hyps: List[List[str]]) -> List[float]:\n",
    "        if len(refs) != len(hyps):\n",
    "            raise ValueError(f\"ì°¸ì¡°ì™€ ì˜ˆì¸¡ ë°ì´í„°ì˜ ê¸¸ì´ê°€ ë‹¤ë¦…ë‹ˆë‹¤: {len(refs)} vs {len(hyps)}\")\n",
    "        \n",
    "        scores = []\n",
    "        for ref, hyp in zip(refs, hyps):\n",
    "            score = hierarchical_f1(ref, hyp)\n",
    "            scores.append(score)\n",
    "        \n",
    "        return scores\n",
    "\n",
    "# ëŒ€íšŒ ì œê³µ FairnessScore í´ë˜ìŠ¤ (100% ë™ì¼)\n",
    "class FairnessScore:\n",
    "    def __init__(self, bin_width: int = 10, min_samples_per_group: int = 1):\n",
    "        self.bin_width = int(bin_width)\n",
    "        self.min_samples_per_group = int(min_samples_per_group)\n",
    "        self.last_stats = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_1d(a) -> np.ndarray:\n",
    "        a = np.asarray(a)\n",
    "        if a.ndim == 2 and a.shape[1] == 1:\n",
    "            a = a[:, 0]\n",
    "        if a.ndim != 1:\n",
    "            raise ValueError(\"Input must be 1D or (N,1) shaped.\")\n",
    "        return a\n",
    "\n",
    "    def _bin_ages(self, ages) -> np.ndarray:\n",
    "        a = self._ensure_1d(ages).astype(float)\n",
    "        if np.any(np.isnan(a)):\n",
    "            raise ValueError(\"ages contain NaN.\")\n",
    "        if self.bin_width <= 0:\n",
    "            raise ValueError(\"bin_width must be positive.\")\n",
    "        starts = (np.floor(a / self.bin_width) * self.bin_width).astype(int)\n",
    "        ends = starts + self.bin_width\n",
    "        labels = np.array([f\"{s:d}-{e:d}\" for s, e in zip(starts, ends)], dtype=object)\n",
    "        return labels\n",
    "\n",
    "    def _groups_from_type(self, groups, type: str) -> np.ndarray:\n",
    "        t = (type or \"sex\").lower()\n",
    "        if t not in (\"sex\", \"age\"):\n",
    "            raise ValueError(\"type must be 'sex' or 'age'.\")\n",
    "        if t == \"sex\":\n",
    "            g = self._ensure_1d(groups)\n",
    "            return g\n",
    "        else:\n",
    "            return self._bin_ages(groups)\n",
    "\n",
    "    def __call__(self, groups, scores, type: str = \"sex\", sample_weight=None) -> float:\n",
    "        g = self._groups_from_type(groups, type=type)\n",
    "        s = self._ensure_1d(scores).astype(float)\n",
    "        if s.shape[0] != g.shape[0]:\n",
    "            raise ValueError(\"groups and scores must have the same length.\")\n",
    "\n",
    "        if sample_weight is None:\n",
    "            w = np.ones_like(s, dtype=float)\n",
    "        else:\n",
    "            w = self._ensure_1d(sample_weight).astype(float)\n",
    "            if w.shape[0] != s.shape[0]:\n",
    "                raise ValueError(\"sample_weight length must match scores.\")\n",
    "\n",
    "        s = np.clip(s, 0.0, 1.0)\n",
    "\n",
    "        uniq = np.unique(g)\n",
    "        means = []\n",
    "        by_group = {}\n",
    "        for grp in uniq:\n",
    "            mask = (g == grp)\n",
    "            if np.sum(mask) < self.min_samples_per_group:\n",
    "                continue\n",
    "            denom = np.sum(w[mask])\n",
    "            if denom <= 0:\n",
    "                continue\n",
    "            m = float(np.average(s[mask], weights=w[mask]))\n",
    "            means.append(m)\n",
    "            by_group[str(grp)] = m\n",
    "\n",
    "        if len(means) <= 1:\n",
    "            self.last_stats = {\"by_group\": by_group, \"gap\": 0.0, \"min\": None, \"max\": None}\n",
    "            return 1.0\n",
    "\n",
    "        max_m = float(np.max(means))\n",
    "        min_m = float(np.min(means))\n",
    "        fairness = 1.0 if max_m == 0.0 else float(min_m / max_m)\n",
    "        fairness = float(np.clip(fairness, 0.0, 1.0))\n",
    "\n",
    "        self.last_stats = {\"by_group\": by_group, \"gap\": max_m - min_m, \"min\": min_m, \"max\": max_m}\n",
    "        return fairness\n",
    "\n",
    "# TaskC Processor (ì•ì„œ ì‘ì„±í•œ ì½”ë“œ)\n",
    "class TaskCProcessor:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        \n",
    "        config = ModelConfig(\n",
    "            # model_name=\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ\",\n",
    "            model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "            api_base=\"https://api.snubhai.org/api/v1/llm\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=2000,\n",
    "            seed=777,\n",
    "            provider=\"openai\"\n",
    "        )\n",
    "        \n",
    "        self.llm = LLMFactory.create_llm(config, temperature=0, rpm=10)\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.get_prompt_template())\n",
    "        self.chain = self.prompt_template | self.llm\n",
    "\n",
    "    def get_prompt_template(self) -> str:\n",
    "        return \"\"\"You are an expert medical coder with 10+ years of experience in ICD-10 coding. Analyze the hospital course and assign the most appropriate ICD-10 codes.\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Focus on PRIMARY diagnoses and significant conditions only\n",
    "- Use exact ICD-10 format (e.g., I82431, S066X1A)\n",
    "- Maintain consistent coding standards regardless of patient demographics\n",
    "- Prioritize conditions that required active treatment during admission\n",
    "- Consider hierarchical relationships in ICD-10 classification\n",
    "\n",
    "CODING METHODOLOGY:\n",
    "1. Identify Chief Complaint and primary reason for admission\n",
    "2. Extract documented diagnoses from medical record\n",
    "3. Prioritize active conditions over chronic stable conditions\n",
    "4. Apply appropriate specificity and laterality codes\n",
    "5. Include significant complications or comorbidities\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "HOSPITAL COURSE: Patient with traumatic brain injury following fall...\n",
    "Service: NEUROSURGERY\n",
    "Chief Complaint: Head trauma\n",
    "History: Fall from ladder with loss of consciousness...\n",
    "Physical Exam: GCS 14, focal neurological deficits...\n",
    "Imaging: CT head shows subdural hematoma...\n",
    "CODES: S066X1A, W1830XA\n",
    "\n",
    "HOSPITAL COURSE: Elderly female with urinary retention and back pain...  \n",
    "Service: MEDICINE\n",
    "Chief Complaint: Unable to urinate, back pain\n",
    "History: Progressive back pain over 2 weeks, now with urinary retention...\n",
    "Past Medical History: Osteoporosis, hypertension...\n",
    "MRI: Lumbar spinal stenosis at L4-5...\n",
    "CODES: M5489, R339\n",
    "\n",
    "HOSPITAL COURSE: Middle-aged male presents with acute chest pain...\n",
    "Service: NEUROSURGERY  \n",
    "Chief Complaint: Sudden severe headache\n",
    "History: Sudden onset worst headache of life, found down at home...\n",
    "CT: Subarachnoid hemorrhage, no aneurysm identified...\n",
    "CODES: I609, R001\n",
    "\n",
    "Now analyze this hospital course and provide ICD-10 codes:\n",
    "\n",
    "HOSPITAL COURSE: {user_input}\n",
    "\n",
    "CODES:\"\"\"\n",
    "\n",
    "    async def preprocess_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        hospital_course = data['hospital_course']\n",
    "        \n",
    "        if pd.isna(hospital_course) or not isinstance(hospital_course, str):\n",
    "            return {'user_input': ''}\n",
    "        \n",
    "        important_sections = []\n",
    "        \n",
    "        # Chief Complaint ì¶”ì¶œ\n",
    "        if 'Chief Complaint:' in hospital_course:\n",
    "            cc_match = re.search(r'Chief Complaint:\\s*([^\\n]+)', hospital_course)\n",
    "            if cc_match:\n",
    "                important_sections.append(f\"Chief Complaint: {cc_match.group(1).strip()}\")\n",
    "        \n",
    "        # Service ì¶”ì¶œ\n",
    "        if 'Service:' in hospital_course:\n",
    "            service_match = re.search(r'Service:\\s*([^\\n]+)', hospital_course)\n",
    "            if service_match:\n",
    "                important_sections.append(f\"Service: {service_match.group(1).strip()}\")\n",
    "        \n",
    "        # History of Present Illness ì¶”ì¶œ\n",
    "        if 'History of Present Illness:' in hospital_course:\n",
    "            hpi_match = re.search(r'History of Present Illness:\\s*(.*?)(?=\\n\\n|\\nPast Medical|$)', \n",
    "                                hospital_course, re.DOTALL)\n",
    "            if hpi_match:\n",
    "                hpi = hpi_match.group(1).strip()[:500]\n",
    "                important_sections.append(f\"History: {hpi}\")\n",
    "        \n",
    "        # Past Medical History ì¶”ì¶œ\n",
    "        if 'Past Medical History:' in hospital_course:\n",
    "            pmh_match = re.search(r'Past Medical History:\\s*(.*?)(?=\\n\\n|PAST SURGICAL|Social History|$)',\n",
    "                                hospital_course, re.DOTALL)\n",
    "            if pmh_match:\n",
    "                pmh = pmh_match.group(1).strip()[:300]\n",
    "                important_sections.append(f\"Past Medical History: {pmh}\")\n",
    "        \n",
    "        # Imaging IMPRESSION ì¶”ì¶œ\n",
    "        impressions = re.findall(r'IMPRESSION:\\s*(.*?)(?=\\n\\n|\\n[A-Z_]|\\Z)', hospital_course, re.DOTALL)\n",
    "        if impressions:\n",
    "            for i, imp in enumerate(impressions[:2]):\n",
    "                important_sections.append(f\"Imaging {i+1}: {imp.strip()[:200]}\")\n",
    "        \n",
    "        processed_text = '\\n\\n'.join(important_sections)\n",
    "        processed_text = re.sub(r'___+', '[REDACTED]', processed_text)\n",
    "        processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
    "        processed_text = processed_text[:2000]\n",
    "        \n",
    "        return {'user_input': processed_text.strip()}\n",
    "    \n",
    "    async def postprocess_result(self, result: str) -> str:\n",
    "        result = result.strip()\n",
    "        \n",
    "        if result.startswith(('CODES:', 'codes:', 'Codes:')):\n",
    "            result = result.split(':', 1)[1].strip()\n",
    "        \n",
    "        icd_pattern = r'[A-Z]\\d{2}[A-Z0-9]*'\n",
    "        codes = re.findall(icd_pattern, result.upper())\n",
    "        unique_codes = list(dict.fromkeys(codes))\n",
    "        \n",
    "        if not unique_codes:\n",
    "            fallback_pattern = r'[A-Z]+\\d+[A-Z0-9]*'\n",
    "            codes = re.findall(fallback_pattern, result.upper())\n",
    "            unique_codes = list(dict.fromkeys(codes))[:3]\n",
    "        \n",
    "        final_codes = unique_codes[:5]\n",
    "        \n",
    "        if not final_codes:\n",
    "            return 'Z515'\n",
    "        \n",
    "        return ', '.join(final_codes)\n",
    "\n",
    "# ë¦¬ë”ë³´ë“œ ë™ì¼ í‰ê°€ í•¨ìˆ˜\n",
    "async def exact_taskc_evaluation(train_csv_path: str, api_key: str):\n",
    "    \"\"\"ëŒ€íšŒ ë¦¬ë”ë³´ë“œì™€ ì •í™•íˆ ë™ì¼í•œ Task C í‰ê°€\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ† Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹œë®¬ë ˆì´ì…˜\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    print(\"1. ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "    df = pd.read_csv(train_csv_path)\n",
    "    df = df.dropna(subset=['hospital_course', 'target'])\n",
    "    \n",
    "    eval_samples = min(300, len(df))\n",
    "    eval_df = df.iloc[:eval_samples].copy()\n",
    "    print(f\"í‰ê°€ ìƒ˜í”Œ: {eval_samples}ê°œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í¬:\")\n",
    "    print(f\"ì„±ë³„: {eval_df['gender'].value_counts().to_dict()}\")\n",
    "    print(f\"ì—°ë ¹: í‰ê·  {eval_df['anchor_age'].mean():.1f}ì„¸\")\n",
    "    \n",
    "    # 2. TaskC ì²˜ë¦¬ê¸° ì´ˆê¸°í™”\n",
    "    print(\"\\n2. TaskC ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (EXAONE ëª¨ë¸)...\")\n",
    "    processor = TaskCProcessor(api_key)\n",
    "    \n",
    "    # 3. ì˜ˆì¸¡ ìƒì„±\n",
    "    print(\"3. ICD ì½”ë“œ ì˜ˆì¸¡ ìƒì„± ì¤‘...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    data_batch = [{'hospital_course': row['hospital_course']} for _, row in eval_df.iterrows()]\n",
    "    \n",
    "    results = []\n",
    "    batch_size = 8\n",
    "    \n",
    "    for i in range(0, len(data_batch), batch_size):\n",
    "        batch = data_batch[i:i+batch_size]\n",
    "        print(f\"   ë°°ì¹˜ {i//batch_size + 1}/{(len(data_batch)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ì „ì²˜ë¦¬\n",
    "        preprocessed = [await processor.preprocess_data(row) for row in batch]\n",
    "        \n",
    "        # API í˜¸ì¶œ\n",
    "        tasks = [processor.chain.ainvoke(prep) for prep in preprocessed]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # í›„ì²˜ë¦¬\n",
    "        batch_results = [await processor.postprocess_result(r.content) for r in responses]\n",
    "        results.extend(batch_results)\n",
    "        \n",
    "        # API ì œí•œ ì¤€ìˆ˜\n",
    "        if i + batch_size < len(data_batch):\n",
    "            print(f\"   API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 70ì´ˆ ëŒ€ê¸°...\")\n",
    "            await asyncio.sleep(70)\n",
    "    \n",
    "    predictions = results\n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {generation_time:.1f}ì´ˆ)\")\n",
    "    \n",
    "    # 4. ì •ë‹µ ë°ì´í„° ì¤€ë¹„ (ëŒ€íšŒ í˜•ì‹ê³¼ ë™ì¼)\n",
    "    references = eval_df['target'].tolist()\n",
    "    \n",
    "    # ICD ì½”ë“œ íŒŒì‹± (ëŒ€íšŒ í‰ê°€ì™€ ë™ì¼)\n",
    "    print(\"\\n4. ICD ì½”ë“œ íŒŒì‹± ì¤‘...\")\n",
    "    ref_codes = [parse_icd_codes(ref) for ref in references]\n",
    "    pred_codes = [parse_icd_codes(pred) for pred in predictions]\n",
    "    \n",
    "    print(f\"íŒŒì‹± ì™„ë£Œ: ì •ë‹µ {len(ref_codes)}ê°œ, ì˜ˆì¸¡ {len(pred_codes)}ê°œ\")\n",
    "    \n",
    "    # 5. ICDScore ê³„ì‚° (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
    "    print(\"5. ICDScore ê³„ì‚° ì¤‘...\")\n",
    "    icd_scorer = ICDScore()\n",
    "    icd_scores = icd_scorer(refs=ref_codes, hyps=pred_codes)\n",
    "    icd_mean = np.mean(icd_scores)\n",
    "    icd_std = np.std(icd_scores)\n",
    "    \n",
    "    # 6. ê³µì •ì„± ì§€í‘œ ê³„ì‚° (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\n",
    "    print(\"6. ê³µì •ì„± ì§€í‘œ ê³„ì‚° ì¤‘...\")\n",
    "    fairness_scorer = FairnessScore(bin_width=10, min_samples_per_group=1)\n",
    "    \n",
    "    # ì„±ë³„ ê³µì •ì„±\n",
    "    gender_fairness = fairness_scorer(\n",
    "        groups=eval_df['gender'].tolist(),\n",
    "        scores=icd_scores,\n",
    "        type='sex'\n",
    "    )\n",
    "    gender_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # ì—°ë ¹ ê³µì •ì„±\n",
    "    age_fairness = fairness_scorer(\n",
    "        groups=eval_df['anchor_age'].tolist(),\n",
    "        scores=icd_scores,\n",
    "        type='age'  \n",
    "    )\n",
    "    age_stats = fairness_scorer.last_stats\n",
    "    \n",
    "    # 7. ëŒ€íšŒ ì •í™•í•œ ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ¯ Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"ğŸ“Š ICDScore (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\")\n",
    "    print(f\"   í‰ê· : {icd_mean:.6f}\")\n",
    "    print(f\"   í‘œì¤€í¸ì°¨: {icd_std:.6f}\")\n",
    "    print(f\"   ìµœê³ : {max(icd_scores):.6f}\")\n",
    "    print(f\"   ìµœì €: {min(icd_scores):.6f}\")\n",
    "    print(f\"   ì¤‘ì•™ê°’: {np.median(icd_scores):.6f}\")\n",
    "    \n",
    "    print(f\"\\nâš–ï¸ ê³µì •ì„± ì§€í‘œ (ëŒ€íšŒ ê³µì‹ ê³„ì‚°)\")\n",
    "    print(f\"   ì„±ë³„ ê³µì •ì„±: {gender_fairness:.6f}\")\n",
    "    print(f\"   ì„±ë³„ë³„ ì„±ëŠ¥: {gender_stats['by_group']}\")\n",
    "    print(f\"   ì„±ë³„ ê²©ì°¨: {gender_stats['gap']:.6f}\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   ì—°ë ¹ ê³µì •ì„±: {age_fairness:.6f}\")\n",
    "    print(f\"   ì—°ë ¹ëŒ€ë³„ ì„±ëŠ¥: {age_stats['by_group']}\")\n",
    "    print(f\"   ì—°ë ¹ ê²©ì°¨: {age_stats['gap']:.6f}\")\n",
    "    \n",
    "    # 8. ì •ëŸ‰ í‰ê°€ ì ìˆ˜ ê³„ì‚° (Task CëŠ” 9ì  ë§Œì )\n",
    "    print(f\"\\nğŸ† Task C ì •ëŸ‰ í‰ê°€ ì ìˆ˜\")\n",
    "    \n",
    "    # ICDScore ì ìˆ˜ (6ì  ë§Œì  - 9ì ì˜ 2/3)\n",
    "    icd_score_points = min(6.0, max(0.0, (icd_mean / 0.70) * 6.0))  # ëª©í‘œ 0.70\n",
    "    \n",
    "    # ê³µì •ì„± ì ìˆ˜ (3ì  ë§Œì  - 9ì ì˜ 1/3)\n",
    "    fairness_avg = (gender_fairness + age_fairness) / 2.0\n",
    "    fairness_points = min(3.0, max(0.0, (fairness_avg / 0.95) * 3.0))\n",
    "    \n",
    "    # ì´ì \n",
    "    total_quantitative = icd_score_points + fairness_points\n",
    "    \n",
    "    print(f\"   ICDScore: {icd_score_points:.3f}/6.000 ì \")\n",
    "    print(f\"   ê³µì •ì„± ì§€í‘œ: {fairness_points:.3f}/3.000 ì \")\n",
    "    print(f\"   ì •ëŸ‰ ì´ì : {total_quantitative:.3f}/9.000 ì \")\n",
    "    print(f\"   ì •ëŸ‰ ë‹¬ì„±ë¥ : {total_quantitative/9.0*100:.1f}%\")\n",
    "    \n",
    "    # 9. ì„±ëŠ¥ ë“±ê¸‰ íŒì •\n",
    "    print(f\"\\nğŸ–ï¸ ì„±ëŠ¥ ë“±ê¸‰\")\n",
    "    if total_quantitative >= 7.5:\n",
    "        grade = \"Sê¸‰ (ìµœìš°ìˆ˜)\"\n",
    "        recommendation = \"ì¦‰ì‹œ ì œì¶œ ê¶Œì¥\"\n",
    "    elif total_quantitative >= 6.5:\n",
    "        grade = \"Aê¸‰ (ìš°ìˆ˜)\"\n",
    "        recommendation = \"ì œì¶œ ê¶Œì¥\"\n",
    "    elif total_quantitative >= 5.5:\n",
    "        grade = \"Bê¸‰ (ì–‘í˜¸)\"\n",
    "        recommendation = \"ì†Œí­ ê°œì„  í›„ ì œì¶œ\"\n",
    "    else:\n",
    "        grade = \"Cê¸‰ (ë³´í†µ)\"\n",
    "        recommendation = \"ê°œì„  í•„ìš”\"\n",
    "    \n",
    "    print(f\"   ë“±ê¸‰: {grade}\")\n",
    "    print(f\"   ê¶Œì¥ì‚¬í•­: {recommendation}\")\n",
    "    \n",
    "    # 10. ì˜ˆì¸¡ ìƒ˜í”Œ ë¶„ì„\n",
    "    print(f\"\\nğŸ“ ì˜ˆì¸¡ í’ˆì§ˆ ìƒ˜í”Œ (ìƒìœ„/í•˜ìœ„ ê° 3ê°œ)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    sorted_indices = np.argsort(icd_scores)\n",
    "    \n",
    "    print(\"ğŸ† ìµœê³  ì„±ëŠ¥ ìƒ˜í”Œ:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[-(i+1)]\n",
    "        print(f\"ìƒ˜í”Œ {idx} (ICDScore: {icd_scores[idx]:.4f})\")\n",
    "        print(f\"ì •ë‹µ: {ref_codes[idx]}\")\n",
    "        print(f\"ì˜ˆì¸¡: {pred_codes[idx]}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"âš ï¸ ìµœì € ì„±ëŠ¥ ìƒ˜í”Œ:\")\n",
    "    for i in range(3):\n",
    "        idx = sorted_indices[i]\n",
    "        print(f\"ìƒ˜í”Œ {idx} (ICDScore: {icd_scores[idx]:.4f})\")\n",
    "        print(f\"ì •ë‹µ: {ref_codes[idx]}\")\n",
    "        print(f\"ì˜ˆì¸¡: {pred_codes[idx]}\")\n",
    "        print()\n",
    "    \n",
    "    return {\n",
    "        'icd_score_mean': icd_mean,\n",
    "        'icd_score_std': icd_std,\n",
    "        'icd_scores': icd_scores,\n",
    "        'gender_fairness': gender_fairness,\n",
    "        'age_fairness': age_fairness,\n",
    "        'total_score': total_quantitative,\n",
    "        'grade': grade,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'evaluation_samples': eval_samples,\n",
    "        'processing_time': generation_time\n",
    "    }\n",
    "\n",
    "# ì‹¤í–‰\n",
    "API_KEY = \"cfa06ca698c85aa9c9d4b55440aeef0f85ed94f644cd7b931fdd69f2421c6ecb\"\n",
    "TRAIN_CSV_PATH = \"./data/taskC_train.csv\"\n",
    "\n",
    "# Task C ë¦¬ë”ë³´ë“œ ì •í™• í‰ê°€ ì‹¤í–‰\n",
    "taskc_results = await exact_taskc_evaluation(\n",
    "    train_csv_path=TRAIN_CSV_PATH,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ‰ Task C ë¦¬ë”ë³´ë“œ í‰ê°€ ì™„ë£Œ!\")\n",
    "print(f\"ìµœì¢… ì˜ˆìƒ ì ìˆ˜: {taskc_results['total_score']:.3f}/9.000 ì \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c2b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
